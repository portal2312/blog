<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>README | Portal2312&#39;s blog</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="README" />
<meta name="author" content="mkkim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="학습 목표: * 텐서플로우의 기초 개념을 학습한다 * 텐서플로우의 LinearRegressor 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측한다 * 평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가한다 * 초매개변수를 조정하여 모델의 정확성을 개선한다" />
<meta property="og:description" content="학습 목표: * 텐서플로우의 기초 개념을 학습한다 * 텐서플로우의 LinearRegressor 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측한다 * 평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가한다 * 초매개변수를 조정하여 모델의 정확성을 개선한다" />
<link rel="canonical" href="/blog/docs/develop/A-M/machine-learning/google/link/TensorFlow%20%EC%B2%AB%EA%B1%B8%EC%9D%8C/READMD.html" />
<meta property="og:url" content="/blog/docs/develop/A-M/machine-learning/google/link/TensorFlow%20%EC%B2%AB%EA%B1%B8%EC%9D%8C/READMD.html" />
<meta property="og:site_name" content="Portal2312&#39;s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-12-02T16:38:51+09:00" />
<script type="application/ld+json">
{"description":"학습 목표: * 텐서플로우의 기초 개념을 학습한다 * 텐서플로우의 LinearRegressor 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측한다 * 평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가한다 * 초매개변수를 조정하여 모델의 정확성을 개선한다","headline":"README","dateModified":"2019-12-02T16:38:51+09:00","datePublished":"2019-12-02T16:38:51+09:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/blog/docs/develop/A-M/machine-learning/google/link/TensorFlow%20%EC%B2%AB%EA%B1%B8%EC%9D%8C/READMD.html"},"url":"/blog/docs/develop/A-M/machine-learning/google/link/TensorFlow%20%EC%B2%AB%EA%B1%B8%EC%9D%8C/READMD.html","author":{"@type":"Person","name":"mkkim"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href='/blog/assets/main.css'><link type="application/atom+xml" rel="alternate" href="/blog/feed.xml" title="Portal2312's blog" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113063601-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script src='/blog/dist/js/common.bundle.js'></script>
</head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/blog/">Portal2312&#39;s blog</a>
    <nav class="site-nav">
    <input type="checkbox" id="nav-trigger" class="nav-trigger" />
    <label for="nav-trigger">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
        </svg>
      </span>
    </label>

    <div class="trigger"><a class="page-link" href="/blog/about.html">
            About
          </a><a class="page-link" href="/blog/posts.html">
            Posts
          </a><a class="page-link" href="/blog/history.html">
            History
          </a><a class="page-link" href="/blog/docs/index.html">
            Docs
          </a></div>
  </nav>
  </div>
  <div class="scroll-indicator-container">
  <div class="scroll-indicator-bar" id="scrollIndicatorBar"></div>
</div>

</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1>README</h1>

  <div>
    <h2>Table of contents</h2>
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#part-65438130afa">설정</a></li>
<li class="toc-entry toc-h2"><a href="#part-26a86f439fe4c022">데이터 조사</a></li>
<li class="toc-entry toc-h2"><a href="#part-93a8fb6f8d6555fd">첫 번째 모델 만들기</a>
<ul>
<li class="toc-entry toc-h3"><a href="#1">1단계: 특성 정의 및 특성 열 구성</a></li>
<li class="toc-entry toc-h3"><a href="#2">2단계: 타겟 정의</a></li>
<li class="toc-entry toc-h3"><a href="#3-linearregressor">3단계: LinearRegressor 구성</a></li>
<li class="toc-entry toc-h3"><a href="#4">4단계: 입력 함수 정의</a></li>
<li class="toc-entry toc-h3"><a href="#5">5단계: 모델 학습</a></li>
<li class="toc-entry toc-h3"><a href="#6">6단계: 모델 평가</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#part-9f37e7ad534ffe0e">모델 초매개변수 조정</a></li>
<li class="toc-entry toc-h2"><a href="#1-180-rmse">작업 1: 180 이하의 RMSE 달성</a>
<ul>
<li class="toc-entry toc-h3"><a href="#part-606b64351882ea1d">해결 방법</a></li>
<li class="toc-entry toc-h3"><a href="#part-7ca94f58e45aacd0">모델 조정에 대한 표준 휴리스틱이 있는가?</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#2">작업 2: 다른 특성 실험</a></li>
<li class="toc-entry toc-h2"><a href="#reference">Reference</a></li>
</ul><p><strong>학습 목표:</strong>
* 텐서플로우의 기초 개념을 학습한다
* 텐서플로우의 <code>LinearRegressor</code> 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측한다
* 평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가한다
* 초매개변수를 조정하여 모델의 정확성을 개선한다</p>

<h2 id="part-65438130afa">
<a class="anchor" href="#part-65438130afa" aria-hidden="true"><span class="octicon octicon-link"></span></a>설정</h2>

<p>라이브러리 로드:</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">gridspec</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s">'{:.1f}'</span><span class="o">.</span><span class="nb">format</span>
</code></pre></div>
<p>데이터 세트 로드:</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv"</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="mi">0</span>         <span class="o">-</span><span class="mf">114.3</span>      <span class="mf">34.2</span>                <span class="mf">15.0</span>  <span class="o">...</span>       <span class="mf">472.0</span>            <span class="mf">1.5</span>             <span class="mf">66900.0</span>
<span class="mi">1</span>         <span class="o">-</span><span class="mf">114.5</span>      <span class="mf">34.4</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">463.0</span>            <span class="mf">1.8</span>             <span class="mf">80100.0</span>
<span class="mi">2</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.7</span>                <span class="mf">17.0</span>  <span class="o">...</span>       <span class="mf">117.0</span>            <span class="mf">1.7</span>             <span class="mf">85700.0</span>
<span class="mi">3</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.6</span>                <span class="mf">14.0</span>  <span class="o">...</span>       <span class="mf">226.0</span>            <span class="mf">3.2</span>             <span class="mf">73400.0</span>
<span class="mi">4</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.6</span>                <span class="mf">20.0</span>  <span class="o">...</span>       <span class="mf">262.0</span>            <span class="mf">1.9</span>             <span class="mf">65500.0</span>
<span class="o">...</span>          <span class="o">...</span>       <span class="o">...</span>                 <span class="o">...</span>  <span class="o">...</span>         <span class="o">...</span>            <span class="o">...</span>                 <span class="o">...</span>
<span class="mi">16995</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.6</span>                <span class="mf">52.0</span>  <span class="o">...</span>       <span class="mf">369.0</span>            <span class="mf">2.4</span>            <span class="mf">111400.0</span>
<span class="mi">16996</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.7</span>                <span class="mf">36.0</span>  <span class="o">...</span>       <span class="mf">465.0</span>            <span class="mf">2.5</span>             <span class="mf">79000.0</span>
<span class="mi">16997</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">41.8</span>                <span class="mf">17.0</span>  <span class="o">...</span>       <span class="mf">456.0</span>            <span class="mf">3.0</span>            <span class="mf">103600.0</span>
<span class="mi">16998</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">41.8</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">478.0</span>            <span class="mf">2.0</span>             <span class="mf">85800.0</span>
<span class="mi">16999</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.5</span>                <span class="mf">52.0</span>  <span class="o">...</span>       <span class="mf">270.0</span>            <span class="mf">3.0</span>             <span class="mf">94600.0</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<p>확률적 경사하강법의 성능에 악영향을 줄 수 있는 의도치 않은 정렬 효과를 방지하고자 데이터를 무작위로 추출하겠습니다.
또한 일반적으로 사용하는 학습률 범위에서 보다 쉽게 학습할 수 있도록 <code>median_house_value</code>(주택 가격)를 천 단위로 조정하겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
<span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span> <span class="o">/=</span> <span class="mf">1000.0</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="mi">5867</span>      <span class="o">-</span><span class="mf">118.2</span>      <span class="mf">33.9</span>                <span class="mf">45.0</span>  <span class="o">...</span>       <span class="mf">373.0</span>            <span class="mf">4.0</span>               <span class="mf">157.5</span>
<span class="mi">14319</span>     <span class="o">-</span><span class="mf">122.1</span>      <span class="mf">37.7</span>                <span class="mf">25.0</span>  <span class="o">...</span>       <span class="mf">595.0</span>            <span class="mf">4.4</span>               <span class="mf">209.2</span>
<span class="mi">3777</span>      <span class="o">-</span><span class="mf">117.9</span>      <span class="mf">34.1</span>                <span class="mf">33.0</span>  <span class="o">...</span>       <span class="mf">138.0</span>            <span class="mf">4.5</span>               <span class="mf">220.1</span>
<span class="mi">160</span>       <span class="o">-</span><span class="mf">116.2</span>      <span class="mf">33.7</span>                <span class="mf">38.0</span>  <span class="o">...</span>       <span class="mf">305.0</span>            <span class="mf">2.1</span>                <span class="mf">68.5</span>
<span class="mi">9171</span>      <span class="o">-</span><span class="mf">119.0</span>      <span class="mf">35.3</span>                <span class="mf">34.0</span>  <span class="o">...</span>       <span class="mf">408.0</span>            <span class="mf">3.0</span>                <span class="mf">68.5</span>
<span class="o">...</span>          <span class="o">...</span>       <span class="o">...</span>                 <span class="o">...</span>  <span class="o">...</span>         <span class="o">...</span>            <span class="o">...</span>                 <span class="o">...</span>
<span class="mi">2054</span>      <span class="o">-</span><span class="mf">117.3</span>      <span class="mf">34.1</span>                <span class="mf">30.0</span>  <span class="o">...</span>       <span class="mf">311.0</span>            <span class="mf">2.2</span>                <span class="mf">93.2</span>
<span class="mi">7921</span>      <span class="o">-</span><span class="mf">118.4</span>      <span class="mf">33.9</span>                <span class="mf">36.0</span>  <span class="o">...</span>       <span class="mf">494.0</span>            <span class="mf">7.3</span>               <span class="mf">500.0</span>
<span class="mi">3937</span>      <span class="o">-</span><span class="mf">118.0</span>      <span class="mf">34.0</span>                <span class="mf">25.0</span>  <span class="o">...</span>       <span class="mf">200.0</span>            <span class="mf">5.3</span>               <span class="mf">297.6</span>
<span class="mi">9642</span>      <span class="o">-</span><span class="mf">119.5</span>      <span class="mf">36.7</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">542.0</span>            <span class="mf">3.3</span>               <span class="mf">160.1</span>
<span class="mi">13698</span>     <span class="o">-</span><span class="mf">122.0</span>      <span class="mf">37.0</span>                <span class="mf">42.0</span>  <span class="o">...</span>       <span class="mf">200.0</span>            <span class="mf">4.7</span>               <span class="mf">422.4</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<h2 id="part-26a86f439fe4c022">
<a class="anchor" href="#part-26a86f439fe4c022" aria-hidden="true"><span class="octicon octicon-link"></span></a>데이터 조사</h2>

<p>데이터를 본격적으로 다루기 전에 잠시 살펴보는 것이 좋습니다.</p>

<p>각 열에 대해 예의 개수, 평균, 표준편차, 최대값, 최소값, 다양한 분위 등 몇 가지 유용한 통계를 간단히 요약하여 출력해 보겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="n">count</span>    <span class="mf">17000.0</span>   <span class="mf">17000.0</span>             <span class="mf">17000.0</span>  <span class="o">...</span>     <span class="mf">17000.0</span>        <span class="mf">17000.0</span>             <span class="mf">17000.0</span>
<span class="n">mean</span>      <span class="o">-</span><span class="mf">119.6</span>      <span class="mf">35.6</span>                <span class="mf">28.6</span>  <span class="o">...</span>       <span class="mf">501.2</span>            <span class="mf">3.9</span>               <span class="mf">207.3</span>
<span class="n">std</span>          <span class="mf">2.0</span>       <span class="mf">2.1</span>                <span class="mf">12.6</span>  <span class="o">...</span>       <span class="mf">384.5</span>            <span class="mf">1.9</span>               <span class="mf">116.0</span>
<span class="nb">min</span>       <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">32.5</span>                 <span class="mf">1.0</span>  <span class="o">...</span>         <span class="mf">1.0</span>            <span class="mf">0.5</span>                <span class="mf">15.0</span>
<span class="mi">25</span><span class="o">%</span>       <span class="o">-</span><span class="mf">121.8</span>      <span class="mf">33.9</span>                <span class="mf">18.0</span>  <span class="o">...</span>       <span class="mf">282.0</span>            <span class="mf">2.6</span>               <span class="mf">119.4</span>
<span class="mi">50</span><span class="o">%</span>       <span class="o">-</span><span class="mf">118.5</span>      <span class="mf">34.2</span>                <span class="mf">29.0</span>  <span class="o">...</span>       <span class="mf">409.0</span>            <span class="mf">3.5</span>               <span class="mf">180.4</span>
<span class="mi">75</span><span class="o">%</span>       <span class="o">-</span><span class="mf">118.0</span>      <span class="mf">37.7</span>                <span class="mf">37.0</span>  <span class="o">...</span>       <span class="mf">605.2</span>            <span class="mf">4.8</span>               <span class="mf">265.0</span>
<span class="nb">max</span>       <span class="o">-</span><span class="mf">114.3</span>      <span class="mf">42.0</span>                <span class="mf">52.0</span>  <span class="o">...</span>      <span class="mf">6082.0</span>           <span class="mf">15.0</span>               <span class="mf">500.0</span>

<span class="p">[</span><span class="mi">8</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<h2 id="part-93a8fb6f8d6555fd">
<a class="anchor" href="#part-93a8fb6f8d6555fd" aria-hidden="true"><span class="octicon octicon-link"></span></a>첫 번째 모델 만들기</h2>

<p>이 실습에서는 라벨(타겟이라고도 함) 역할을 하는 <code>median_house_value</code>(집 값)에 대한 예측을 시도합니다. 입력 특성으로는 <code>total_rooms</code>(방 총수)를 사용합니다.</p>

<p><strong>참고:</strong> 데이터는 지역 단위이므로 이 특성은 해당 지역의 전체 방 수를 나타냅니다.</p>

<p>모델을 학습시키려면 텐서플로우 <a href="https://www.tensorflow.org/get_started/estimator">Estimator</a> API가 제공하는 <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor">LinearRegressor</a> 인터페이스를 사용합니다. 이 API는 저수준 모델 작업을 알아서 처리하고 모델 학습, 평가, 추론을 수행하는 데 편리하게 사용되는 메소드를 노출합니다.</p>

<h3 id="1">
<a class="anchor" href="#1" aria-hidden="true"><span class="octicon octicon-link"></span></a>1단계: 특성 정의 및 특성 열 구성</h3>

<p>학습 데이터를 텐서플로우로 가져오려면 각 특성에 들어있는 데이터 유형을 지정해야 합니다. 이 실습과 이후 실습에서는 주로 2가지 데이터 유형을 사용합니다.</p>

<ul>
<li><p><strong>범주형 데이터</strong>: 텍스트로 이루어진 데이터입니다. 이 실습의 주택 데이터 세트는 범주형 데이터를 포함하지 않지만 주택 양식, 부동산 광고 문구 등의 예를 보게 될 수도 있습니다.</p></li>
<li><p><strong>수치 데이터</strong>: 정수 또는 부동 소수점 숫자이며 숫자로 취급하려는 데이터입니다. 이후에도 설명하겠지만, 우편번호 등의 수치 데이터는 범주형으로 취급하는 경우도 있습니다.</p></li>
</ul>

<p>텐서플로우에서 특성의 데이터 유형을 지정하려면 <strong>특성 열</strong>이라는 구조체를 사용합니다. 특성 열은 특성 데이터에 대한 설명만 저장하며 특성 데이터 자체는 포함하지 않습니다.</p>

<p>우선은 <code>total_rooms</code>(방 총수)라는 수치 입력 데이터 하나만 사용하겠습니다. 다음 코드에서는 <code>california_housing_dataframe</code>에서 <code>total_rooms</code>(방 총수) 데이터를 추출하고 <code>numeric_column</code>으로 특성 열을 정의하여 데이터가 숫자임을 지정합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Define the input feature: total_rooms.
</span><span class="n">my_feature</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[[</span><span class="s">"total_rooms"</span><span class="p">]]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py">       <span class="n">total_rooms</span>
<span class="mi">5867</span>        <span class="mf">1818.0</span>
<span class="mi">14319</span>       <span class="mf">2973.0</span>
<span class="mi">3777</span>         <span class="mf">859.0</span>
<span class="mi">160</span>         <span class="mf">1695.0</span>
<span class="mi">9171</span>        <span class="mf">2221.0</span>
<span class="o">...</span>            <span class="o">...</span>
<span class="mi">2054</span>        <span class="mf">2335.0</span>
<span class="mi">7921</span>        <span class="mf">3022.0</span>
<span class="mi">3937</span>        <span class="mf">1348.0</span>
<span class="mi">9642</span>        <span class="mf">3351.0</span>
<span class="mi">13698</span>       <span class="mf">1275.0</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">1</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Configure a numeric feature column for total_rooms.
</span><span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="s">"total_rooms"</span><span class="p">)]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># california_housing_dataframe["total_rooms"] 의 items 가져오기
</span><span class="k">print</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span>

<span class="p">[</span><span class="n">NumericColumn</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'total_rooms'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">default_value</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)]</span>
</code></pre></div>
<h3 id="2">
<a class="anchor" href="#2" aria-hidden="true"><span class="octicon octicon-link"></span></a>2단계: 타겟 정의</h3>

<p>다음으로는 타겟인 <code>median_house_value</code>(방 값)를 정의합니다. 이 데이터도 <code>california_housing_dataframe</code>에서 가져옵니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Define the label.
</span><span class="n">targets</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="mi">5867</span>    <span class="mf">157.5</span>
<span class="mi">14319</span>   <span class="mf">209.2</span>
<span class="mi">3777</span>    <span class="mf">220.1</span>
<span class="mi">160</span>      <span class="mf">68.5</span>
<span class="mi">9171</span>     <span class="mf">68.5</span>
         <span class="o">...</span> 
<span class="mi">2054</span>     <span class="mf">93.2</span>
<span class="mi">7921</span>    <span class="mf">500.0</span>
<span class="mi">3937</span>    <span class="mf">297.6</span>
<span class="mi">9642</span>    <span class="mf">160.1</span>
<span class="mi">13698</span>   <span class="mf">422.4</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">median_house_value</span><span class="p">,</span> <span class="n">Length</span><span class="p">:</span> <span class="mi">17000</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</code></pre></div>
<h3 id="3-linearregressor">
<a class="anchor" href="#3-linearregressor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3단계: LinearRegressor 구성</h3>

<p>다음으로는 LinearRegressor를 사용하여 선형 회귀 모델을구성합니다. <a href="">미니 배치 확률적 경사하강법(SGD)</a>을 구현하는 <code>GradientDescentOptimizer</code>를 사용하여 이 모델을 학습시킬 것입니다. <code>learning_rate</code> 인수는 경사 단계의 크기를 조절합니다.</p>

<p><strong>참고:</strong> 안전을 위해 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#optimizer">옵티마이저</a>에 <code>clip_gradients_by_norm</code>을 통해 <a href="https://developers.google.com/machine-learning/glossary/#gradient_clipping">경사 제한</a>을 적용합니다. 경사 제한은 학습 중에 경사가 너무 커져서 경사하강법이 실패하는 경우가 나타나지 않도록 제한합니다. </p>

<blockquote>
<p><strong>미니 배치 확률적 경사하강법(SGD)</strong><br>
<a href="https://developers.google.com/machine-learning/glossary/?hl=ko#mini-batch">미니 배치</a>를 사용하는 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#gradient_descent">경사하강법</a> 알고리즘입니다.<br>
즉, 미니 배치 SGD는 학습 데이터 중 작은 부분집합을 기반으로 경사를 예측합니다.<br>
<a href="https://developers.google.com/machine-learning/glossary/?hl=ko#SGD">기본적인 SGD</a>에서는 크기가 <strong>1</strong>인 미니 배치를 사용합니다.</p>

<p><strong>미니 배치(mini-batch)</strong><br>
학습 또는 추론의 단일 반복에서 함께 실행되는 예의 전체 배치 중에서 무작위로 선택한 소규모 부분집합입니다.<br>
미니 배치의 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#batch_size">배치 크기</a>는 일반적으로 10~1,000입니다.<br>
전체 학습 데이터가 아닌 미니 배치의 손실을 계산하면 효율성이 크게 향상됩니다.</p>

<p><strong>배치 크기(batch size)</strong><br>
배치 하나에 포함되는 예의 개수입니다.<br>
예를 들어 SGD의 배치 크기는 <strong>1</strong>이고, 미니 배치의 배치 크기는 일반적으로 10~1,000입니다.<br>
학습 및 추론 중에 배치 크기는 일반적으로 고정되지만, 텐서플로우는 동적 배치 크기를 허용합니다.</p>

<p><strong>경사하강법(gradient descent)</strong><br>
학습 데이터의 조건에 따라 모델의 매개변수를 기준으로 <a href="">손실</a>의 경사를 계산하여 손실을 최소화하는 기법입니다.<br>
쉽게 설명하면, 경사하강법은 매개변수를 반복적으로 조정하면서 손실을 최소화하는 <a href="">가중치</a>와 <a href="">편향</a>의 가장 적절한 조합을 점진적으로 찾는 방식입니다.</p>

<p><strong>확률적 경사하강법(SGD, stochastic gradient descent)</strong><br>
배치 크기가 <strong>1</strong>인 <a href="">경사하강법</a> 알고리즘입니다.<br>
즉, 확률적 경사하강법은 데이터 세트에서 무작위로 균일하게 선택한 하나의 예에 의존하여 각 단계의 예측 경사를 계산합니다.</p>
</blockquote>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Use gradient descent as the optimizer for training the model.
# 경사하강법으로 모델 트레이닝하기
# 경사 기울기(learning_rate) 0.0000001 설정하기
</span><span class="n">my_optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">)</span>

<span class="c1"># contrib 코드는 휘발성 코드 또는 실험 코드를 포함합니다.
# 경사 제한(5.0) 설정하기
</span><span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">clip_gradients_by_norm</span><span class="p">(</span><span class="n">my_optimizer</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

<span class="c1"># Configure the linear regression model with our feature columns and optimizer.
# Set a learning rate of 0.0000001 for Gradient Descent.
</span><span class="n">linear_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">LinearRegressor</span><span class="p">(</span>
    <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">my_optimizer</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="4">
<a class="anchor" href="#4" aria-hidden="true"><span class="octicon octicon-link"></span></a>4단계: 입력 함수 정의</h3>

<p>캘리포니아 주택 데이터를 <code>LinearRegressor</code>로 가져오려면 텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의해야 합니다.</p>

<p>우선 <em>pandas</em> 특성 데이터를 NumPy 배열의 dict로 변환합니다. 그런 다음 텐서플로우의 <a href="https://www.tensorflow.org/programmers_guide/datasets">Dataset API</a>를 사용하여 이 데이터로부터 데이터 세트 개체를 생성하고 <code>batch_size</code> 크기의 배치로 나누어 지정한 세대 수(num_epochs)만큼 반복합니다.</p>

<p><strong>참고:</strong> 기본값인 <code>num_epochs=None</code>을 <code>repeat()</code>에 전달하면 입력 데이터가 무한정 반복됩니다.</p>

<p>다음으로, <code>shuffle</code>을 <code>True</code>로 설정하면 학습 중에 데이터가 모델에 무작위로 전달되도록 데이터가 뒤섞입니다. <code>buffer_size</code> 인수는 <code>shuffle</code>에서 무작위로 추출할 데이터 세트의 크기를 지정합니다.</p>

<p>마지막으로 입력 함수에서 데이터 세트에 대한 반복자를 만들고 다음 데이터 배치를 LinearRegressor에 반환합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">my_input_fn</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""Trains a linear regression model of one feature.

    Args:
      features: pandas DataFrame of features
      targets: pandas DataFrame of targets
      batch_size: Size of batches to be passed to the model
      shuffle: True or False. Whether to shuffle the data.
      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely
    Returns:
      Tuple of (features, labels) for next data batch
    """</span>

    <span class="c1"># Convert pandas data into a dict of np arrays.
</span>    <span class="n">features</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="c1"># features = {'total_rooms': array([1818., 2973., ..., 1275.])}
</span>
    <span class="c1"># Construct a dataset, and configure batching/repeating.
</span>    <span class="c1"># from_tensor_slices(): 데이터 집합을 구성
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">features</span><span class="p">,</span><span class="n">targets</span><span class="p">))</span> <span class="c1"># warning: 2GB limit
</span>    <span class="c1"># 데이터 집할을 일괄 처리/반복을 구성합니다.
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

    <span class="c1"># Shuffle the data, if specified.
</span>    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

    <span class="c1"># Return the next batch of data.
</span>    <span class="c1"># make_one_shot_iterator():
</span>    <span class="c1">#   데이터 집합의 요소를 열거하기위한 tf.data.Iterator를 만듭니다.
</span>    <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">make_one_shot_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>
<h3 id="5">
<a class="anchor" href="#5" aria-hidden="true"><span class="octicon octicon-link"></span></a>5단계: 모델 학습</h3>

<p>이제 linear_regressor로부터 train()을 호출하여 모델을 학습시킬 수 있습니다.<br>
<code>my_feature</code> 및 <code>target</code>을 인수로 전달할 수 있도록 <code>my_input_fn</code>을 <code>lambda</code>에 래핑하겠습니다.<br>
자세한 내용은 <a href="https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model">텐서플로우 입력 함수 가이드</a>를 참조하세요.<br>
처음에는 100단계만 학습하려고 합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">_</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span><span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature</span><span class="p">,</span> <span class="n">targets</span><span class="p">),</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="6">
<a class="anchor" href="#6" aria-hidden="true"><span class="octicon octicon-link"></span></a>6단계: 모델 평가</h3>

<p>모델이 학습 중에 학습 데이터에 얼마나 맞춰졌는지 확인하기 위해 학습 데이터로 예측을 실행하겠습니다.</p>

<p><strong>참고:</strong> 학습 오차는 모델이 학습 데이터에 얼마나 맞춰졌는지를 나타내는 척도이지만 모델이 <strong><em>새 데이터로 일반화</em></strong>되는 정도를 측정하지는 <strong><em>않습니다.</em></strong> 이후 실습에서는 모델의 일반화 능력을 평가할 수 있도록 데이터를 분할하는 방법을 알아봅니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Create an input function for predictions.
# Note: Since we're making just one prediction for each example, we don't 
# need to repeat or shuffle the data here.
# 예측 값을 가공할 함수 정의
# num_epochs: 데이터 전처리 방법 및 모델 학습 중의 반복 방법
</span><span class="n">prediction_input_fn</span> <span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Call predict() on the linear_regressor to make predictions.
# 예측하기
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">prediction_input_fn</span><span class="p">)</span>

<span class="c1"># Format predictions as a NumPy array, so we can calculate error metrics.
# 예측 결과 가져오기
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
<span class="c1"># [0.09089997 0.14864993 0.04295    ... 0.06739999 0.16754992 0.06374999]
</span>
<span class="c1"># Print Mean Squared Error and Root Mean Squared Error.
# 평균 제곱 오차(mean_squared_error) 계산하기
</span><span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="c1"># 평균 제곱근 오차(math.sqrt(mean_squared_error) 계산하기
</span><span class="n">root_mean_squared_error</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean Squared Error (on training data): </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Root Mean Squared Error (on training data): </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>

<span class="c1"># Mean Squared Error (on training data): 56367.025
# Root Mean Squared Error (on training data): 237.417
</span></code></pre></div>
<p>우수한 모델인가요? 이 오차가 얼마나 큰지 어떻게 판단할 수 있을까요?</p>

<p>평균 제곱 오차(MSE)는 해석하기가 어려울 수 있으므로 평균 제곱근 오차(RMSE)를 대신 참고하는 경우가 많습니다.<br>
RMSE의 장점은 원래 타겟과 동일한 척도로 해석할 수 있다는 것입니다.</p>

<p>RMSE를 타겟의 최소값과 최대값의 차와 비교해 보겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">min_house_value</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">max_house_value</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">min_max_difference</span> <span class="o">=</span> <span class="n">max_house_value</span> <span class="o">-</span> <span class="n">min_house_value</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Min. Median House Value: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">min_house_value</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Max. Median House Value: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">max_house_value</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Difference between Min. and Max.: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">min_max_difference</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Root Mean Squared Error: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>

<span class="c1"># Min. Median House Value: 14.999
# Max. Median House Value: 500.001
# Difference between Min. and Max.: 485.002
# Root Mean Squared Error: 237.417
</span></code></pre></div>
<p>오차 범위가 타겟 값 범위의 거의 절반에 달합니다. 오차를 이보다 줄일 수 있을까요?</p>

<p>이 질문이야말로 모든 모델 개발자들의 숙제입니다. 모델 오차를 줄이는 몇 가지 기본적인 전략을 수립해 보겠습니다.</p>

<p>가장 처음에 할 수 있는 일은 전반적 요약 통계를 참조하여 예측과 타겟의 일치율을 조사하는 것입니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">calibration_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">calibration_data</span><span class="p">[</span><span class="s">"predictions"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="n">calibration_data</span><span class="p">[</span><span class="s">"targets"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
<span class="n">calibration_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>

<span class="c1">#        predictions  targets
# count      17000.0  17000.0
# mean           0.1    207.3
# std            0.1    116.0
# min            0.0     15.0
# 25%            0.1    119.4
# 50%            0.1    180.4
# 75%            0.2    265.0
# max            1.9    500.0
</span></code></pre></div>
<p>이 정보는 유용해 보입니다. 평균 값을 모델의 RMSE와 비교해 보면 어떠한가요? 다양한 분위는 어떠한가요?</p>

<p>학습한 데이터와 선을 시각화할 수도 있습니다. 단일 특성에 대한 선형 회귀는 입력 x를 출력 y에 매핑하는 직선으로 표현될 수 있습니다.</p>

<p>우선 판독 가능한 산포도를 그릴 수 있도록 균일한 무작위 데이터 샘플을 추출하겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">sample</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1">#        longitude  latitude  housing_median_age  ...  households  median_income  median_house_value
# 16672     -122.8      38.4                14.0  ...       629.0            4.0               345.3
# 12084     -121.4      38.6                46.0  ...       457.0            3.6               142.0
# 2836      -117.7      34.1                37.0  ...       530.0            5.9               226.0
# 5669      -118.2      33.9                38.0  ...       832.0            3.7               169.8
# 7967      -118.4      34.0                49.0  ...       106.0            8.0               500.0
# ...          ...       ...                 ...  ...         ...            ...                 ...
# 8874      -118.8      34.3                27.0  ...       268.0            5.1               185.2
# 10080     -119.8      36.6                34.0  ...       407.0            1.8                74.2
# 638       -117.0      34.0                30.0  ...       691.0            2.6                98.3
# 2089      -117.3      33.9                13.0  ...      1176.0            5.6               214.5
# 7845      -118.4      33.9                17.0  ...       341.0            4.4               349.0
# 
# [300 rows x 9 columns]
</span></code></pre></div>
<p>다음으로는 산포도와 함께 모델의 바이어스 항와 특성 가중치를 바탕으로 학습한 선을 그리겠습니다. 이 선은 빨간색으로 표시됩니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Get the min and max total_rooms values.
</span><span class="n">x_0</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>

<span class="c1"># 훈련 중 생성 된 최종 체중 및 바이어스를 검색합니다.
# print(linear_regressor.get_variable_names())
# ['global_step',
#  'linear/linear_model/bias_weights',
#  'linear/linear_model/total_rooms/weights'] 
</span><span class="n">weight</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/total_rooms/weights'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/bias_weights'</span><span class="p">)</span>

<span class="c1"># Get the predicted median_house_values for the min and max total_rooms values.
</span><span class="n">y_0</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">bias</span> 
<span class="n">y_1</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">bias</span>

<span class="c1"># Plot our regression line from (x_0, y_0) to (x_1, y_1).
# 회귀 선 그리기 (x_0, y_0) 부터 (x_1, y_1) 까지
</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">],</span> <span class="p">[</span><span class="n">y_0</span><span class="p">,</span> <span class="n">y_1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>

<span class="c1"># Label the graph axes.
# Label 정의하기
</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"median_house_value"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"total_rooms"</span><span class="p">)</span>

<span class="c1"># Plot a scatter plot from our data sample.
# 데이터 샘플에서 산점도를 그리기
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">])</span>

<span class="c1"># Display graph.
</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img src="img/006.png" alt="006.png"></p>

<p>이 최초 선은 상당히 이탈된 상태입니다. 요약 통계를 다시 조사하여 이 선이 나타내는 정보와 부합하는지 확인해 보세요.</p>

<p>이러한 초기 상태 확인을 통해 훨씬 더 나은 선을 찾을 수 있다는 점을 알 수 있습니다.</p>

<h2 id="part-9f37e7ad534ffe0e">
<a class="anchor" href="#part-9f37e7ad534ffe0e" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 초매개변수 조정</h2>

<p>이 실습에서는 편의를 위해 위 모든 코드를 단일 함수에 넣었습니다.<br>
다른 매개변수로 함수를 호출하여 효과를 확인할 수 있습니다.</p>

<p>이 함수에서 균등하게 <strong>10</strong>개로 나눈 기간으로 학습을 진행하여 모델의 개선을 기간별로 살펴보겠습니다.</p>

<p>각 기간에 대한 학습 손실을 계산하고 그래프로 그리겠습니다.<br>
이를 통해 모델이 수렴되는 시점을 판단하거나 반복이 더 필요함을 확인할 수 있습니다.</p>

<p>또한 모델이 학습한 특성 가중치와 바이어스 항을 시간별로 도식화하겠습니다.<br>
이는 모델이 수렴되는 모습을 확인하는 또 다른 방법입니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_feature</span><span class="o">=</span><span class="s">"total_rooms"</span><span class="p">):</span>
  <span class="s">"""Trains a linear regression model of one feature.

  Args:
    learning_rate: A `float`, the learning rate.
    steps: A non-zero `int`, the total number of training steps. A training step
      consists of a forward and backward pass using a single batch.
    batch_size: A non-zero `int`, the batch size.
    input_feature: A `string` specifying a column from `california_housing_dataframe`
      to use as input feature.
  """</span>

  <span class="n">periods</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">steps_per_period</span> <span class="o">=</span> <span class="n">steps</span> <span class="o">/</span> <span class="n">periods</span>

  <span class="n">my_feature</span> <span class="o">=</span> <span class="n">input_feature</span>  <span class="c1"># 특성 명
</span>  <span class="n">my_feature_data</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[[</span><span class="n">my_feature</span><span class="p">]]</span>  <span class="c1"># 특성 데이터 가져오기
</span>  <span class="n">my_label</span> <span class="o">=</span> <span class="s">"median_house_value"</span>  <span class="c1"># 예측 명
</span>  <span class="n">targets</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="n">my_label</span><span class="p">]</span>  <span class="c1"># 예측 데이터 가져오기
</span>
  <span class="c1"># Create feature columns.
</span>  <span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)]</span>  <span class="c1"># 특성 데이터를 특성 (숫자)열로 가공하기
</span>
  <span class="c1"># Create input functions.
</span>  <span class="c1"># 텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의해야 합니다.
</span>  <span class="n">training_input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span><span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># 학습할 입력 합수 (특성 데이터, 예측 데이터, 작업할 수)
</span>  <span class="n">prediction_input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># 예측할 입력 함수 (특성 데이터, 예측 데이터, 학습 반복 수, 데이터 섞기)
</span>
  <span class="c1"># Create a linear regressor object.
</span>  <span class="c1"># 경사 하강법 최적화기 생성(기울기)
</span>  <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

  <span class="c1"># 기울기 최대값 지정
</span>  <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">clip_gradients_by_norm</span><span class="p">(</span><span class="n">my_optimizer</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

  <span class="c1"># 선형 회귀자 사용하기(특성 데이터 숫자 열, )
</span>  <span class="n">linear_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">LinearRegressor</span><span class="p">(</span>
      <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>  <span class="c1"># 특성 열 지정하기
</span>      <span class="n">optimizer</span><span class="o">=</span><span class="n">my_optimizer</span>  <span class="c1">#최적화기 지정하기
</span>  <span class="p">)</span>

  <span class="c1"># Set up to plot the state of our model's line each period.
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># 새로운 그림 생성하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 현재 그림에 하위 그림을 추가하기, nrows, ncols, index
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learned Line by Period"</span><span class="p">)</span>  <span class="c1"># 제목 정의하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">my_label</span><span class="p">)</span>  <span class="c1"># Y 축 label 명 정의하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)</span>  <span class="c1"># X 축 label 명 정의하기
</span>  <span class="n">sample</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>  <span class="c1"># 전체 data 중 300 행을 sample로 가져오기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="n">my_label</span><span class="p">])</span>  <span class="c1"># sample 을 그림에 추가하기(그리기)
</span>
  <span class="c1"># cm(matplotlib/cm.py): 내장 된 색상 맵, 색상 맵 처리 유틸리티 및 `ScalarMappable` 섞기 
</span>  <span class="c1"># -1 부터 1 까지 균일한 간격(periods=10)의 array([])
</span>  <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">periods</span><span class="p">)]</span>
  <span class="c1"># print(np.linspace(-1, 1, periods))
</span>  <span class="c1"># array([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,
</span>  <span class="c1">#       0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ])
</span>  <span class="c1">#
</span>  <span class="c1"># print(colors)
</span>  <span class="c1"># [(0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.3634607953411765, 0.4847836818509804, 0.9010188868941177, 1.0),
</span>  <span class="c1">#  (0.6672529243333334, 0.7791764569999999, 0.992959213, 1.0),
</span>  <span class="c1">#  (0.9193759889058823, 0.8312727235294118, 0.7828736304470588, 1.0),
</span>  <span class="c1">#  (0.9440545734235294, 0.5531534787490197, 0.4355484903137255, 1.0),
</span>  <span class="c1">#  (0.705673158, 0.01555616, 0.150232812, 1.0)]
</span>

  <span class="c1"># Train the model, but do so inside a loop so that we can periodically assess
</span>  <span class="c1"># loss metrics.
</span>  <span class="k">print</span><span class="p">(</span><span class="s">"Training model..."</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"RMSE (on training data):"</span><span class="p">)</span>
  <span class="n">root_mean_squared_errors</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">period</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">periods</span><span class="p">):</span>  <span class="c1"># (0, 10)
</span>    <span class="c1"># Train the model, starting from the prior state.
</span>    <span class="c1"># 모델을 학습, 이전 상태에서 시작
</span>    <span class="n">linear_regressor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
        <span class="n">input_fn</span><span class="o">=</span><span class="n">training_input_fn</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps_per_period</span>  <span class="c1"># =step/periods
</span>    <span class="p">)</span>
    <span class="c1"># Take a break and compute predictions.
</span>    <span class="c1"># 예측하기(학습된 모델 기반으로)
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">prediction_input_fn</span><span class="p">)</span>
    <span class="c1"># 예측된 결과 값만 가져오기
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>

    <span class="c1"># Compute loss.
</span>    <span class="n">root_mean_squared_error</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>  <span class="c1"># 제곱근 처리하기(RMSE)
</span>        <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">))</span>  <span class="c1"># 손실율 계산하기(MSE)
</span>    <span class="c1"># Occasionally print the current loss.
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"  period </span><span class="si">%02</span><span class="s">d : </span><span class="si">%0.2</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">period</span><span class="p">,</span> <span class="n">root_mean_squared_error</span><span class="p">))</span>
    <span class="c1"># Add the loss metrics from this period to our list.
</span>    <span class="n">root_mean_squared_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_mean_squared_error</span><span class="p">)</span>
    <span class="c1"># Finally, track the weights and biases over time.
</span>    <span class="c1"># 시간에 따른 가중치와 편향구하기
</span>    <span class="c1"># Apply some math to ensure that the data and line are plotted neatly.
</span>    <span class="c1"># 몇 가지 수학을 적용하여 데이터와 선이 깔끔하게 정리하기
</span>    <span class="c1"># Y 범위 (sample의 0 부터 Y(target) 최대 값)
</span>    <span class="n">y_extents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="n">my_label</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()])</span>

    <span class="c1"># 특성의 가중치
</span>    <span class="n">weight</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/</span><span class="si">%</span><span class="s">s/weights'</span> <span class="o">%</span> <span class="n">input_feature</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 편향(원점 기준의 한 절편, w1, w2, ..)
</span>    <span class="n">bias</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/bias_weights'</span><span class="p">)</span>
    <span class="n">x_extents</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_extents</span> <span class="o">-</span> <span class="n">bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">weight</span>  <span class="c1"># 션형관계(y=d+w*x)를 이용한 X 구하기
</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'{x_extents} = ({y_extents} - {bias}) / {weight}'</span><span class="p">)</span>
    <span class="n">x_extents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x_extents</span><span class="p">,</span>
                                      <span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()),</span>
                           <span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">())</span>
    <span class="n">y_extents</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_extents</span> <span class="o">+</span> <span class="n">bias</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'{y_extents} = {weight} * {x_extents} + {bias}'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_extents</span><span class="p">,</span> <span class="n">y_extents</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">period</span><span class="p">])</span> 
  <span class="k">print</span><span class="p">(</span><span class="s">"Model training finished."</span><span class="p">)</span>

  <span class="c1"># Output a graph of loss metrics over periods.
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'RMSE'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Periods'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Root Mean Squared Error vs. Periods"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="k">print</span><span class="p">(</span><span class="n">root_mean_squared_errors</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">root_mean_squared_errors</span><span class="p">)</span>

  <span class="c1"># Output a table with calibration data.
</span>  <span class="n">calibration_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
  <span class="n">calibration_data</span><span class="p">[</span><span class="s">"predictions"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
  <span class="n">calibration_data</span><span class="p">[</span><span class="s">"targets"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
  <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">calibration_data</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

  <span class="k">print</span><span class="p">(</span><span class="s">"Final RMSE (on training data): </span><span class="si">%0.2</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>
</code></pre></div>
<h2 id="1-180-rmse">
<a class="anchor" href="#1-180-rmse" aria-hidden="true"><span class="octicon octicon-link"></span></a>작업 1: 180 이하의 RMSE 달성</h2>

<p>모델 초매개변수를 조정하여 타겟 분포와 더 잘 일치하도록 손실을 개선합니다.
5분이 지나도록 RMSE를 180 이하로 떨어뜨리지 못한 경우 해결 방법에을 확인하여 가능한 조합을 알아보세요.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">236.32</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">235.11</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">233.90</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">232.70</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">231.50</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">230.31</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">229.13</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">227.96</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">226.79</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">225.63</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
       <span class="n">predictions</span>  <span class="n">targets</span>
<span class="n">count</span>      <span class="mf">17000.0</span>  <span class="mf">17000.0</span>
<span class="n">mean</span>          <span class="mf">13.2</span>    <span class="mf">207.3</span>
<span class="n">std</span>           <span class="mf">10.9</span>    <span class="mf">116.0</span>
<span class="nb">min</span>            <span class="mf">0.0</span>     <span class="mf">15.0</span>
<span class="mi">25</span><span class="o">%</span>            <span class="mf">7.3</span>    <span class="mf">119.4</span>
<span class="mi">50</span><span class="o">%</span>           <span class="mf">10.6</span>    <span class="mf">180.4</span>
<span class="mi">75</span><span class="o">%</span>           <span class="mf">15.8</span>    <span class="mf">265.0</span>
<span class="nb">max</span>          <span class="mf">189.7</span>    <span class="mf">500.0</span>
<span class="n">Final</span> <span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span> <span class="mf">225.63</span>
</code></pre></div>
<p><img src="img/%EB%AA%A8%EB%8D%B8%20%EC%B4%88%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%20%EC%A1%B0%EC%A0%95.png" alt="모델 초매개변수 조정.png"></p>

<h3 id="part-606b64351882ea1d">
<a class="anchor" href="#part-606b64351882ea1d" aria-hidden="true"><span class="octicon octicon-link"></span></a>해결 방법</h3>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">225.63</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">214.42</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">204.04</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">194.97</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">186.92</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">180.53</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">175.22</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">171.57</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">169.08</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">167.98</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
</code></pre></div>
<p><img src="img/%EB%AA%A8%EB%8D%B8%20%EC%B4%88%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%20%EC%A1%B0%EC%A0%95%20%ED%95%B4%EA%B2%B0.png" alt="모델 초매개변수 조정 해결.png"></p>

<p>이는 가능한 조합 중 하나일 뿐이며, 우수한 결과를 내는 다른 설정 조합이 있을 수 있습니다.<br>
일반적으로 이 실습의 목적은 최상의 설정을 찾는 것이 아니라 모델 구성을 조정하면 예측 품질에 어떠한 영향을 주는지 감을 잡는 것입니다.</p>

<h3 id="part-7ca94f58e45aacd0">
<a class="anchor" href="#part-7ca94f58e45aacd0" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 조정에 대한 표준 휴리스틱이 있는가?</h3>

<p>흔히 제기되는 질문입니다. 단적으로 말해, 다양한 초매개변수의 효과는 데이터에 따라 다릅니다.<br>
따라서 알기 쉽고 확고한 규칙은 존재하지 않으며, 실제 데이터로 테스트하는 과정이 필요합니다.</p>

<p>그러나 유용하게 참고할 만한 몇 가지 경험칙이 있습니다.</p>

<ul>
<li>학습 오차는 점차 감소합니다. 처음에는 급격히 감소하다가 학습이 수렴됨에 따라 결국 한계에 다다릅니다.</li>
<li>학습이 수렴되지 않았다면 더 오래 실행해 보세요.</li>
<li>학습 오차가 너무 천천히 감소하는 경우 학습률을 높이면 더 빨리 감소할 수 있습니다.

<ul>
<li>학습률이 너무 높다면 정반대 현상이 나타나기도 합니다.</li>
</ul>
</li>
<li>학습 오차가 크게 요동한다면 학습률을 낮춰보세요.

<ul>
<li>학습률을 낮추면서 단계 수 또는 배치 크기를 늘리면 좋은 결과가 나타나는 경우가 많습니다.</li>
</ul>
</li>
<li>배치 크기가 너무 작아도 불안정성이 나타날 수 있습니다. 처음에는 100, 1000 등의 큰 값을 사용한 후 성능이 악화되지 않는 선까지 낮추세요.</li>
</ul>

<p>효과는 데이터에 따라 달라지므로 이러한 경험칙을 무조건적으로 따라서는 안 됩니다.<br>
실험과 검증을 항상 반복하세요.</p>

<blockquote>
<p><strong>휴리스틱(heuristics)</strong>
발견법, 불충분한 시간이나 정보로 인하여 합리적인 판단을 할 수 없거나, 체계적이면서 합리적인
판단이 굳이 필요하지 않은 상황에서 사람들이 빠르게 사용할 수 있는 어림짐작의 방법이다.<br>
ex) 어떤 문제를 이해하기 어렵다면, 그림을 그려본다.</p>
</blockquote>

<h2 id="2">
<a class="anchor" href="#2" aria-hidden="true"><span class="octicon octicon-link"></span></a>작업 2: 다른 특성 실험</h2>

<p><code>total_rooms</code> 특성을 <code>population</code> 특성으로 대체하면 결과가 개선되는지 확인해 봅니다.</p>

<p>이 부분은 최대 5분까지만 진행하시기 바랍니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">input_feature</span><span class="o">=</span><span class="s">"population"</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">225.63</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">214.62</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">204.67</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">195.94</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">189.12</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">183.81</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">180.34</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">178.18</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">176.70</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">176.10</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
</code></pre></div>
<p><img src="img/%EC%9E%91%EC%97%852.png" alt="작업2.png"></p>

<h2 id="reference">
<a class="anchor" href="#reference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reference</h2>

<p><a href="https://developers.google.com/machine-learning/glossary/?hl=ko">머신러닝 용어집</a></p>

  </div>

<div>
  <p><strong>학습 목표:</strong>
* 텐서플로우의 기초 개념을 학습한다
* 텐서플로우의 <code>LinearRegressor</code> 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측한다
* 평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가한다
* 초매개변수를 조정하여 모델의 정확성을 개선한다</p>

<h2 id="part-65438130afa">설정</h2>

<p>라이브러리 로드:</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">gridspec</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s">'{:.1f}'</span><span class="o">.</span><span class="nb">format</span>
</code></pre></div>
<p>데이터 세트 로드:</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv"</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="mi">0</span>         <span class="o">-</span><span class="mf">114.3</span>      <span class="mf">34.2</span>                <span class="mf">15.0</span>  <span class="o">...</span>       <span class="mf">472.0</span>            <span class="mf">1.5</span>             <span class="mf">66900.0</span>
<span class="mi">1</span>         <span class="o">-</span><span class="mf">114.5</span>      <span class="mf">34.4</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">463.0</span>            <span class="mf">1.8</span>             <span class="mf">80100.0</span>
<span class="mi">2</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.7</span>                <span class="mf">17.0</span>  <span class="o">...</span>       <span class="mf">117.0</span>            <span class="mf">1.7</span>             <span class="mf">85700.0</span>
<span class="mi">3</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.6</span>                <span class="mf">14.0</span>  <span class="o">...</span>       <span class="mf">226.0</span>            <span class="mf">3.2</span>             <span class="mf">73400.0</span>
<span class="mi">4</span>         <span class="o">-</span><span class="mf">114.6</span>      <span class="mf">33.6</span>                <span class="mf">20.0</span>  <span class="o">...</span>       <span class="mf">262.0</span>            <span class="mf">1.9</span>             <span class="mf">65500.0</span>
<span class="o">...</span>          <span class="o">...</span>       <span class="o">...</span>                 <span class="o">...</span>  <span class="o">...</span>         <span class="o">...</span>            <span class="o">...</span>                 <span class="o">...</span>
<span class="mi">16995</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.6</span>                <span class="mf">52.0</span>  <span class="o">...</span>       <span class="mf">369.0</span>            <span class="mf">2.4</span>            <span class="mf">111400.0</span>
<span class="mi">16996</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.7</span>                <span class="mf">36.0</span>  <span class="o">...</span>       <span class="mf">465.0</span>            <span class="mf">2.5</span>             <span class="mf">79000.0</span>
<span class="mi">16997</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">41.8</span>                <span class="mf">17.0</span>  <span class="o">...</span>       <span class="mf">456.0</span>            <span class="mf">3.0</span>            <span class="mf">103600.0</span>
<span class="mi">16998</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">41.8</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">478.0</span>            <span class="mf">2.0</span>             <span class="mf">85800.0</span>
<span class="mi">16999</span>     <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">40.5</span>                <span class="mf">52.0</span>  <span class="o">...</span>       <span class="mf">270.0</span>            <span class="mf">3.0</span>             <span class="mf">94600.0</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<p>확률적 경사하강법의 성능에 악영향을 줄 수 있는 의도치 않은 정렬 효과를 방지하고자 데이터를 무작위로 추출하겠습니다.
또한 일반적으로 사용하는 학습률 범위에서 보다 쉽게 학습할 수 있도록 <code>median_house_value</code>(주택 가격)를 천 단위로 조정하겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
<span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span> <span class="o">/=</span> <span class="mf">1000.0</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="mi">5867</span>      <span class="o">-</span><span class="mf">118.2</span>      <span class="mf">33.9</span>                <span class="mf">45.0</span>  <span class="o">...</span>       <span class="mf">373.0</span>            <span class="mf">4.0</span>               <span class="mf">157.5</span>
<span class="mi">14319</span>     <span class="o">-</span><span class="mf">122.1</span>      <span class="mf">37.7</span>                <span class="mf">25.0</span>  <span class="o">...</span>       <span class="mf">595.0</span>            <span class="mf">4.4</span>               <span class="mf">209.2</span>
<span class="mi">3777</span>      <span class="o">-</span><span class="mf">117.9</span>      <span class="mf">34.1</span>                <span class="mf">33.0</span>  <span class="o">...</span>       <span class="mf">138.0</span>            <span class="mf">4.5</span>               <span class="mf">220.1</span>
<span class="mi">160</span>       <span class="o">-</span><span class="mf">116.2</span>      <span class="mf">33.7</span>                <span class="mf">38.0</span>  <span class="o">...</span>       <span class="mf">305.0</span>            <span class="mf">2.1</span>                <span class="mf">68.5</span>
<span class="mi">9171</span>      <span class="o">-</span><span class="mf">119.0</span>      <span class="mf">35.3</span>                <span class="mf">34.0</span>  <span class="o">...</span>       <span class="mf">408.0</span>            <span class="mf">3.0</span>                <span class="mf">68.5</span>
<span class="o">...</span>          <span class="o">...</span>       <span class="o">...</span>                 <span class="o">...</span>  <span class="o">...</span>         <span class="o">...</span>            <span class="o">...</span>                 <span class="o">...</span>
<span class="mi">2054</span>      <span class="o">-</span><span class="mf">117.3</span>      <span class="mf">34.1</span>                <span class="mf">30.0</span>  <span class="o">...</span>       <span class="mf">311.0</span>            <span class="mf">2.2</span>                <span class="mf">93.2</span>
<span class="mi">7921</span>      <span class="o">-</span><span class="mf">118.4</span>      <span class="mf">33.9</span>                <span class="mf">36.0</span>  <span class="o">...</span>       <span class="mf">494.0</span>            <span class="mf">7.3</span>               <span class="mf">500.0</span>
<span class="mi">3937</span>      <span class="o">-</span><span class="mf">118.0</span>      <span class="mf">34.0</span>                <span class="mf">25.0</span>  <span class="o">...</span>       <span class="mf">200.0</span>            <span class="mf">5.3</span>               <span class="mf">297.6</span>
<span class="mi">9642</span>      <span class="o">-</span><span class="mf">119.5</span>      <span class="mf">36.7</span>                <span class="mf">19.0</span>  <span class="o">...</span>       <span class="mf">542.0</span>            <span class="mf">3.3</span>               <span class="mf">160.1</span>
<span class="mi">13698</span>     <span class="o">-</span><span class="mf">122.0</span>      <span class="mf">37.0</span>                <span class="mf">42.0</span>  <span class="o">...</span>       <span class="mf">200.0</span>            <span class="mf">4.7</span>               <span class="mf">422.4</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<h2 id="part-26a86f439fe4c022">데이터 조사</h2>

<p>데이터를 본격적으로 다루기 전에 잠시 살펴보는 것이 좋습니다.</p>

<p>각 열에 대해 예의 개수, 평균, 표준편차, 최대값, 최소값, 다양한 분위 등 몇 가지 유용한 통계를 간단히 요약하여 출력해 보겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="o">...</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="n">count</span>    <span class="mf">17000.0</span>   <span class="mf">17000.0</span>             <span class="mf">17000.0</span>  <span class="o">...</span>     <span class="mf">17000.0</span>        <span class="mf">17000.0</span>             <span class="mf">17000.0</span>
<span class="n">mean</span>      <span class="o">-</span><span class="mf">119.6</span>      <span class="mf">35.6</span>                <span class="mf">28.6</span>  <span class="o">...</span>       <span class="mf">501.2</span>            <span class="mf">3.9</span>               <span class="mf">207.3</span>
<span class="n">std</span>          <span class="mf">2.0</span>       <span class="mf">2.1</span>                <span class="mf">12.6</span>  <span class="o">...</span>       <span class="mf">384.5</span>            <span class="mf">1.9</span>               <span class="mf">116.0</span>
<span class="nb">min</span>       <span class="o">-</span><span class="mf">124.3</span>      <span class="mf">32.5</span>                 <span class="mf">1.0</span>  <span class="o">...</span>         <span class="mf">1.0</span>            <span class="mf">0.5</span>                <span class="mf">15.0</span>
<span class="mi">25</span><span class="o">%</span>       <span class="o">-</span><span class="mf">121.8</span>      <span class="mf">33.9</span>                <span class="mf">18.0</span>  <span class="o">...</span>       <span class="mf">282.0</span>            <span class="mf">2.6</span>               <span class="mf">119.4</span>
<span class="mi">50</span><span class="o">%</span>       <span class="o">-</span><span class="mf">118.5</span>      <span class="mf">34.2</span>                <span class="mf">29.0</span>  <span class="o">...</span>       <span class="mf">409.0</span>            <span class="mf">3.5</span>               <span class="mf">180.4</span>
<span class="mi">75</span><span class="o">%</span>       <span class="o">-</span><span class="mf">118.0</span>      <span class="mf">37.7</span>                <span class="mf">37.0</span>  <span class="o">...</span>       <span class="mf">605.2</span>            <span class="mf">4.8</span>               <span class="mf">265.0</span>
<span class="nb">max</span>       <span class="o">-</span><span class="mf">114.3</span>      <span class="mf">42.0</span>                <span class="mf">52.0</span>  <span class="o">...</span>      <span class="mf">6082.0</span>           <span class="mf">15.0</span>               <span class="mf">500.0</span>

<span class="p">[</span><span class="mi">8</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">9</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div>
<h2 id="part-93a8fb6f8d6555fd">첫 번째 모델 만들기</h2>

<p>이 실습에서는 라벨(타겟이라고도 함) 역할을 하는 <code>median_house_value</code>(집 값)에 대한 예측을 시도합니다. 입력 특성으로는 <code>total_rooms</code>(방 총수)를 사용합니다.</p>

<p><strong>참고:</strong> 데이터는 지역 단위이므로 이 특성은 해당 지역의 전체 방 수를 나타냅니다.</p>

<p>모델을 학습시키려면 텐서플로우 <a href="https://www.tensorflow.org/get_started/estimator" rel="nofollow" target="_blank">Estimator</a> API가 제공하는 <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor" rel="nofollow" target="_blank">LinearRegressor</a> 인터페이스를 사용합니다. 이 API는 저수준 모델 작업을 알아서 처리하고 모델 학습, 평가, 추론을 수행하는 데 편리하게 사용되는 메소드를 노출합니다.</p>

<h3 id="1">1단계: 특성 정의 및 특성 열 구성</h3>

<p>학습 데이터를 텐서플로우로 가져오려면 각 특성에 들어있는 데이터 유형을 지정해야 합니다. 이 실습과 이후 실습에서는 주로 2가지 데이터 유형을 사용합니다.</p>

<ul>
<li><p><strong>범주형 데이터</strong>: 텍스트로 이루어진 데이터입니다. 이 실습의 주택 데이터 세트는 범주형 데이터를 포함하지 않지만 주택 양식, 부동산 광고 문구 등의 예를 보게 될 수도 있습니다.</p></li>
<li><p><strong>수치 데이터</strong>: 정수 또는 부동 소수점 숫자이며 숫자로 취급하려는 데이터입니다. 이후에도 설명하겠지만, 우편번호 등의 수치 데이터는 범주형으로 취급하는 경우도 있습니다.</p></li>
</ul>

<p>텐서플로우에서 특성의 데이터 유형을 지정하려면 <strong>특성 열</strong>이라는 구조체를 사용합니다. 특성 열은 특성 데이터에 대한 설명만 저장하며 특성 데이터 자체는 포함하지 않습니다.</p>

<p>우선은 <code>total_rooms</code>(방 총수)라는 수치 입력 데이터 하나만 사용하겠습니다. 다음 코드에서는 <code>california_housing_dataframe</code>에서 <code>total_rooms</code>(방 총수) 데이터를 추출하고 <code>numeric_column</code>으로 특성 열을 정의하여 데이터가 숫자임을 지정합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Define the input feature: total_rooms.
</span><span class="n">my_feature</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[[</span><span class="s">"total_rooms"</span><span class="p">]]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py">       <span class="n">total_rooms</span>
<span class="mi">5867</span>        <span class="mf">1818.0</span>
<span class="mi">14319</span>       <span class="mf">2973.0</span>
<span class="mi">3777</span>         <span class="mf">859.0</span>
<span class="mi">160</span>         <span class="mf">1695.0</span>
<span class="mi">9171</span>        <span class="mf">2221.0</span>
<span class="o">...</span>            <span class="o">...</span>
<span class="mi">2054</span>        <span class="mf">2335.0</span>
<span class="mi">7921</span>        <span class="mf">3022.0</span>
<span class="mi">3937</span>        <span class="mf">1348.0</span>
<span class="mi">9642</span>        <span class="mf">3351.0</span>
<span class="mi">13698</span>       <span class="mf">1275.0</span>

<span class="p">[</span><span class="mi">17000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">1</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Configure a numeric feature column for total_rooms.
</span><span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="s">"total_rooms"</span><span class="p">)]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># california_housing_dataframe["total_rooms"] 의 items 가져오기
</span><span class="k">print</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span>

<span class="p">[</span><span class="n">NumericColumn</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'total_rooms'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">default_value</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)]</span>
</code></pre></div>
<h3 id="2">2단계: 타겟 정의</h3>

<p>다음으로는 타겟인 <code>median_house_value</code>(방 값)를 정의합니다. 이 데이터도 <code>california_housing_dataframe</code>에서 가져옵니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Define the label.
</span><span class="n">targets</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="mi">5867</span>    <span class="mf">157.5</span>
<span class="mi">14319</span>   <span class="mf">209.2</span>
<span class="mi">3777</span>    <span class="mf">220.1</span>
<span class="mi">160</span>      <span class="mf">68.5</span>
<span class="mi">9171</span>     <span class="mf">68.5</span>
         <span class="o">...</span> 
<span class="mi">2054</span>     <span class="mf">93.2</span>
<span class="mi">7921</span>    <span class="mf">500.0</span>
<span class="mi">3937</span>    <span class="mf">297.6</span>
<span class="mi">9642</span>    <span class="mf">160.1</span>
<span class="mi">13698</span>   <span class="mf">422.4</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">median_house_value</span><span class="p">,</span> <span class="n">Length</span><span class="p">:</span> <span class="mi">17000</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</code></pre></div>
<h3 id="3-linearregressor">3단계: LinearRegressor 구성</h3>

<p>다음으로는 LinearRegressor를 사용하여 선형 회귀 모델을구성합니다. <a href="">미니 배치 확률적 경사하강법(SGD)</a>을 구현하는 <code>GradientDescentOptimizer</code>를 사용하여 이 모델을 학습시킬 것입니다. <code>learning_rate</code> 인수는 경사 단계의 크기를 조절합니다.</p>

<p><strong>참고:</strong> 안전을 위해 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#optimizer" rel="nofollow" target="_blank">옵티마이저</a>에 <code>clip_gradients_by_norm</code>을 통해 <a href="https://developers.google.com/machine-learning/glossary/#gradient_clipping" rel="nofollow" target="_blank">경사 제한</a>을 적용합니다. 경사 제한은 학습 중에 경사가 너무 커져서 경사하강법이 실패하는 경우가 나타나지 않도록 제한합니다. </p>

<blockquote>
<p><strong>미니 배치 확률적 경사하강법(SGD)</strong><br>
<a href="https://developers.google.com/machine-learning/glossary/?hl=ko#mini-batch" rel="nofollow" target="_blank">미니 배치</a>를 사용하는 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#gradient_descent" rel="nofollow" target="_blank">경사하강법</a> 알고리즘입니다.<br>
즉, 미니 배치 SGD는 학습 데이터 중 작은 부분집합을 기반으로 경사를 예측합니다.<br>
<a href="https://developers.google.com/machine-learning/glossary/?hl=ko#SGD" rel="nofollow" target="_blank">기본적인 SGD</a>에서는 크기가 <strong>1</strong>인 미니 배치를 사용합니다.</p>

<p><strong>미니 배치(mini-batch)</strong><br>
학습 또는 추론의 단일 반복에서 함께 실행되는 예의 전체 배치 중에서 무작위로 선택한 소규모 부분집합입니다.<br>
미니 배치의 <a href="https://developers.google.com/machine-learning/glossary/?hl=ko#batch_size" rel="nofollow" target="_blank">배치 크기</a>는 일반적으로 10~1,000입니다.<br>
전체 학습 데이터가 아닌 미니 배치의 손실을 계산하면 효율성이 크게 향상됩니다.</p>

<p><strong>배치 크기(batch size)</strong><br>
배치 하나에 포함되는 예의 개수입니다.<br>
예를 들어 SGD의 배치 크기는 <strong>1</strong>이고, 미니 배치의 배치 크기는 일반적으로 10~1,000입니다.<br>
학습 및 추론 중에 배치 크기는 일반적으로 고정되지만, 텐서플로우는 동적 배치 크기를 허용합니다.</p>

<p><strong>경사하강법(gradient descent)</strong><br>
학습 데이터의 조건에 따라 모델의 매개변수를 기준으로 <a href="">손실</a>의 경사를 계산하여 손실을 최소화하는 기법입니다.<br>
쉽게 설명하면, 경사하강법은 매개변수를 반복적으로 조정하면서 손실을 최소화하는 <a href="">가중치</a>와 <a href="">편향</a>의 가장 적절한 조합을 점진적으로 찾는 방식입니다.</p>

<p><strong>확률적 경사하강법(SGD, stochastic gradient descent)</strong><br>
배치 크기가 <strong>1</strong>인 <a href="">경사하강법</a> 알고리즘입니다.<br>
즉, 확률적 경사하강법은 데이터 세트에서 무작위로 균일하게 선택한 하나의 예에 의존하여 각 단계의 예측 경사를 계산합니다.</p>
</blockquote>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Use gradient descent as the optimizer for training the model.
# 경사하강법으로 모델 트레이닝하기
# 경사 기울기(learning_rate) 0.0000001 설정하기
</span><span class="n">my_optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">)</span>

<span class="c1"># contrib 코드는 휘발성 코드 또는 실험 코드를 포함합니다.
# 경사 제한(5.0) 설정하기
</span><span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">clip_gradients_by_norm</span><span class="p">(</span><span class="n">my_optimizer</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

<span class="c1"># Configure the linear regression model with our feature columns and optimizer.
# Set a learning rate of 0.0000001 for Gradient Descent.
</span><span class="n">linear_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">LinearRegressor</span><span class="p">(</span>
    <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">my_optimizer</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="4">4단계: 입력 함수 정의</h3>

<p>캘리포니아 주택 데이터를 <code>LinearRegressor</code>로 가져오려면 텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의해야 합니다.</p>

<p>우선 <em>pandas</em> 특성 데이터를 NumPy 배열의 dict로 변환합니다. 그런 다음 텐서플로우의 <a href="https://www.tensorflow.org/programmers_guide/datasets" rel="nofollow" target="_blank">Dataset API</a>를 사용하여 이 데이터로부터 데이터 세트 개체를 생성하고 <code>batch_size</code> 크기의 배치로 나누어 지정한 세대 수(num_epochs)만큼 반복합니다.</p>

<p><strong>참고:</strong> 기본값인 <code>num_epochs=None</code>을 <code>repeat()</code>에 전달하면 입력 데이터가 무한정 반복됩니다.</p>

<p>다음으로, <code>shuffle</code>을 <code>True</code>로 설정하면 학습 중에 데이터가 모델에 무작위로 전달되도록 데이터가 뒤섞입니다. <code>buffer_size</code> 인수는 <code>shuffle</code>에서 무작위로 추출할 데이터 세트의 크기를 지정합니다.</p>

<p>마지막으로 입력 함수에서 데이터 세트에 대한 반복자를 만들고 다음 데이터 배치를 LinearRegressor에 반환합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">my_input_fn</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""Trains a linear regression model of one feature.

    Args:
      features: pandas DataFrame of features
      targets: pandas DataFrame of targets
      batch_size: Size of batches to be passed to the model
      shuffle: True or False. Whether to shuffle the data.
      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely
    Returns:
      Tuple of (features, labels) for next data batch
    """</span>

    <span class="c1"># Convert pandas data into a dict of np arrays.
</span>    <span class="n">features</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="c1"># features = {'total_rooms': array([1818., 2973., ..., 1275.])}
</span>
    <span class="c1"># Construct a dataset, and configure batching/repeating.
</span>    <span class="c1"># from_tensor_slices(): 데이터 집합을 구성
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">features</span><span class="p">,</span><span class="n">targets</span><span class="p">))</span> <span class="c1"># warning: 2GB limit
</span>    <span class="c1"># 데이터 집할을 일괄 처리/반복을 구성합니다.
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

    <span class="c1"># Shuffle the data, if specified.
</span>    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

    <span class="c1"># Return the next batch of data.
</span>    <span class="c1"># make_one_shot_iterator():
</span>    <span class="c1">#   데이터 집합의 요소를 열거하기위한 tf.data.Iterator를 만듭니다.
</span>    <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">make_one_shot_iterator</span><span class="p">()</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>
<h3 id="5">5단계: 모델 학습</h3>

<p>이제 linear_regressor로부터 train()을 호출하여 모델을 학습시킬 수 있습니다.<br>
<code>my_feature</code> 및 <code>target</code>을 인수로 전달할 수 있도록 <code>my_input_fn</code>을 <code>lambda</code>에 래핑하겠습니다.<br>
자세한 내용은 <a href="https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model" rel="nofollow" target="_blank">텐서플로우 입력 함수 가이드</a>를 참조하세요.<br>
처음에는 100단계만 학습하려고 합니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">_</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span><span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature</span><span class="p">,</span> <span class="n">targets</span><span class="p">),</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="6">6단계: 모델 평가</h3>

<p>모델이 학습 중에 학습 데이터에 얼마나 맞춰졌는지 확인하기 위해 학습 데이터로 예측을 실행하겠습니다.</p>

<p><strong>참고:</strong> 학습 오차는 모델이 학습 데이터에 얼마나 맞춰졌는지를 나타내는 척도이지만 모델이 <strong><em>새 데이터로 일반화</em></strong>되는 정도를 측정하지는 <strong><em>않습니다.</em></strong> 이후 실습에서는 모델의 일반화 능력을 평가할 수 있도록 데이터를 분할하는 방법을 알아봅니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Create an input function for predictions.
# Note: Since we're making just one prediction for each example, we don't 
# need to repeat or shuffle the data here.
# 예측 값을 가공할 함수 정의
# num_epochs: 데이터 전처리 방법 및 모델 학습 중의 반복 방법
</span><span class="n">prediction_input_fn</span> <span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Call predict() on the linear_regressor to make predictions.
# 예측하기
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">prediction_input_fn</span><span class="p">)</span>

<span class="c1"># Format predictions as a NumPy array, so we can calculate error metrics.
# 예측 결과 가져오기
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
<span class="c1"># [0.09089997 0.14864993 0.04295    ... 0.06739999 0.16754992 0.06374999]
</span>
<span class="c1"># Print Mean Squared Error and Root Mean Squared Error.
# 평균 제곱 오차(mean_squared_error) 계산하기
</span><span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="c1"># 평균 제곱근 오차(math.sqrt(mean_squared_error) 계산하기
</span><span class="n">root_mean_squared_error</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean Squared Error (on training data): </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Root Mean Squared Error (on training data): </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>

<span class="c1"># Mean Squared Error (on training data): 56367.025
# Root Mean Squared Error (on training data): 237.417
</span></code></pre></div>
<p>우수한 모델인가요? 이 오차가 얼마나 큰지 어떻게 판단할 수 있을까요?</p>

<p>평균 제곱 오차(MSE)는 해석하기가 어려울 수 있으므로 평균 제곱근 오차(RMSE)를 대신 참고하는 경우가 많습니다.<br>
RMSE의 장점은 원래 타겟과 동일한 척도로 해석할 수 있다는 것입니다.</p>

<p>RMSE를 타겟의 최소값과 최대값의 차와 비교해 보겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">min_house_value</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">max_house_value</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="n">min_max_difference</span> <span class="o">=</span> <span class="n">max_house_value</span> <span class="o">-</span> <span class="n">min_house_value</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Min. Median House Value: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">min_house_value</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Max. Median House Value: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">max_house_value</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Difference between Min. and Max.: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">min_max_difference</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Root Mean Squared Error: </span><span class="si">%0.3</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>

<span class="c1"># Min. Median House Value: 14.999
# Max. Median House Value: 500.001
# Difference between Min. and Max.: 485.002
# Root Mean Squared Error: 237.417
</span></code></pre></div>
<p>오차 범위가 타겟 값 범위의 거의 절반에 달합니다. 오차를 이보다 줄일 수 있을까요?</p>

<p>이 질문이야말로 모든 모델 개발자들의 숙제입니다. 모델 오차를 줄이는 몇 가지 기본적인 전략을 수립해 보겠습니다.</p>

<p>가장 처음에 할 수 있는 일은 전반적 요약 통계를 참조하여 예측과 타겟의 일치율을 조사하는 것입니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">calibration_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">calibration_data</span><span class="p">[</span><span class="s">"predictions"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="n">calibration_data</span><span class="p">[</span><span class="s">"targets"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
<span class="n">calibration_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>

<span class="c1">#        predictions  targets
# count      17000.0  17000.0
# mean           0.1    207.3
# std            0.1    116.0
# min            0.0     15.0
# 25%            0.1    119.4
# 50%            0.1    180.4
# 75%            0.2    265.0
# max            1.9    500.0
</span></code></pre></div>
<p>이 정보는 유용해 보입니다. 평균 값을 모델의 RMSE와 비교해 보면 어떠한가요? 다양한 분위는 어떠한가요?</p>

<p>학습한 데이터와 선을 시각화할 수도 있습니다. 단일 특성에 대한 선형 회귀는 입력 x를 출력 y에 매핑하는 직선으로 표현될 수 있습니다.</p>

<p>우선 판독 가능한 산포도를 그릴 수 있도록 균일한 무작위 데이터 샘플을 추출하겠습니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">sample</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="c1">#        longitude  latitude  housing_median_age  ...  households  median_income  median_house_value
# 16672     -122.8      38.4                14.0  ...       629.0            4.0               345.3
# 12084     -121.4      38.6                46.0  ...       457.0            3.6               142.0
# 2836      -117.7      34.1                37.0  ...       530.0            5.9               226.0
# 5669      -118.2      33.9                38.0  ...       832.0            3.7               169.8
# 7967      -118.4      34.0                49.0  ...       106.0            8.0               500.0
# ...          ...       ...                 ...  ...         ...            ...                 ...
# 8874      -118.8      34.3                27.0  ...       268.0            5.1               185.2
# 10080     -119.8      36.6                34.0  ...       407.0            1.8                74.2
# 638       -117.0      34.0                30.0  ...       691.0            2.6                98.3
# 2089      -117.3      33.9                13.0  ...      1176.0            5.6               214.5
# 7845      -118.4      33.9                17.0  ...       341.0            4.4               349.0
# 
# [300 rows x 9 columns]
</span></code></pre></div>
<p>다음으로는 산포도와 함께 모델의 바이어스 항와 특성 가중치를 바탕으로 학습한 선을 그리겠습니다. 이 선은 빨간색으로 표시됩니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="c1"># Get the min and max total_rooms values.
</span><span class="n">x_0</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>

<span class="c1"># 훈련 중 생성 된 최종 체중 및 바이어스를 검색합니다.
# print(linear_regressor.get_variable_names())
# ['global_step',
#  'linear/linear_model/bias_weights',
#  'linear/linear_model/total_rooms/weights'] 
</span><span class="n">weight</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/total_rooms/weights'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/bias_weights'</span><span class="p">)</span>

<span class="c1"># Get the predicted median_house_values for the min and max total_rooms values.
</span><span class="n">y_0</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">bias</span> 
<span class="n">y_1</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">bias</span>

<span class="c1"># Plot our regression line from (x_0, y_0) to (x_1, y_1).
# 회귀 선 그리기 (x_0, y_0) 부터 (x_1, y_1) 까지
</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">],</span> <span class="p">[</span><span class="n">y_0</span><span class="p">,</span> <span class="n">y_1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>

<span class="c1"># Label the graph axes.
# Label 정의하기
</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"median_house_value"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"total_rooms"</span><span class="p">)</span>

<span class="c1"># Plot a scatter plot from our data sample.
# 데이터 샘플에서 산점도를 그리기
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">"total_rooms"</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s">"median_house_value"</span><span class="p">])</span>

<span class="c1"># Display graph.
</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img src="img/006.png" alt="006.png"></p>

<p>이 최초 선은 상당히 이탈된 상태입니다. 요약 통계를 다시 조사하여 이 선이 나타내는 정보와 부합하는지 확인해 보세요.</p>

<p>이러한 초기 상태 확인을 통해 훨씬 더 나은 선을 찾을 수 있다는 점을 알 수 있습니다.</p>

<h2 id="part-9f37e7ad534ffe0e">모델 초매개변수 조정</h2>

<p>이 실습에서는 편의를 위해 위 모든 코드를 단일 함수에 넣었습니다.<br>
다른 매개변수로 함수를 호출하여 효과를 확인할 수 있습니다.</p>

<p>이 함수에서 균등하게 <strong>10</strong>개로 나눈 기간으로 학습을 진행하여 모델의 개선을 기간별로 살펴보겠습니다.</p>

<p>각 기간에 대한 학습 손실을 계산하고 그래프로 그리겠습니다.<br>
이를 통해 모델이 수렴되는 시점을 판단하거나 반복이 더 필요함을 확인할 수 있습니다.</p>

<p>또한 모델이 학습한 특성 가중치와 바이어스 항을 시간별로 도식화하겠습니다.<br>
이는 모델이 수렴되는 모습을 확인하는 또 다른 방법입니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_feature</span><span class="o">=</span><span class="s">"total_rooms"</span><span class="p">):</span>
  <span class="s">"""Trains a linear regression model of one feature.

  Args:
    learning_rate: A `float`, the learning rate.
    steps: A non-zero `int`, the total number of training steps. A training step
      consists of a forward and backward pass using a single batch.
    batch_size: A non-zero `int`, the batch size.
    input_feature: A `string` specifying a column from `california_housing_dataframe`
      to use as input feature.
  """</span>

  <span class="n">periods</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">steps_per_period</span> <span class="o">=</span> <span class="n">steps</span> <span class="o">/</span> <span class="n">periods</span>

  <span class="n">my_feature</span> <span class="o">=</span> <span class="n">input_feature</span>  <span class="c1"># 특성 명
</span>  <span class="n">my_feature_data</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[[</span><span class="n">my_feature</span><span class="p">]]</span>  <span class="c1"># 특성 데이터 가져오기
</span>  <span class="n">my_label</span> <span class="o">=</span> <span class="s">"median_house_value"</span>  <span class="c1"># 예측 명
</span>  <span class="n">targets</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="p">[</span><span class="n">my_label</span><span class="p">]</span>  <span class="c1"># 예측 데이터 가져오기
</span>
  <span class="c1"># Create feature columns.
</span>  <span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">feature_column</span><span class="o">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)]</span>  <span class="c1"># 특성 데이터를 특성 (숫자)열로 가공하기
</span>
  <span class="c1"># Create input functions.
</span>  <span class="c1"># 텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의해야 합니다.
</span>  <span class="n">training_input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span><span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># 학습할 입력 합수 (특성 데이터, 예측 데이터, 작업할 수)
</span>  <span class="n">prediction_input_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">my_input_fn</span><span class="p">(</span><span class="n">my_feature_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># 예측할 입력 함수 (특성 데이터, 예측 데이터, 학습 반복 수, 데이터 섞기)
</span>
  <span class="c1"># Create a linear regressor object.
</span>  <span class="c1"># 경사 하강법 최적화기 생성(기울기)
</span>  <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

  <span class="c1"># 기울기 최대값 지정
</span>  <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">clip_gradients_by_norm</span><span class="p">(</span><span class="n">my_optimizer</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

  <span class="c1"># 선형 회귀자 사용하기(특성 데이터 숫자 열, )
</span>  <span class="n">linear_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">LinearRegressor</span><span class="p">(</span>
      <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>  <span class="c1"># 특성 열 지정하기
</span>      <span class="n">optimizer</span><span class="o">=</span><span class="n">my_optimizer</span>  <span class="c1">#최적화기 지정하기
</span>  <span class="p">)</span>

  <span class="c1"># Set up to plot the state of our model's line each period.
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># 새로운 그림 생성하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 현재 그림에 하위 그림을 추가하기, nrows, ncols, index
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learned Line by Period"</span><span class="p">)</span>  <span class="c1"># 제목 정의하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">my_label</span><span class="p">)</span>  <span class="c1"># Y 축 label 명 정의하기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">my_feature</span><span class="p">)</span>  <span class="c1"># X 축 label 명 정의하기
</span>  <span class="n">sample</span> <span class="o">=</span> <span class="n">california_housing_dataframe</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>  <span class="c1"># 전체 data 중 300 행을 sample로 가져오기
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="n">my_label</span><span class="p">])</span>  <span class="c1"># sample 을 그림에 추가하기(그리기)
</span>
  <span class="c1"># cm(matplotlib/cm.py): 내장 된 색상 맵, 색상 맵 처리 유틸리티 및 `ScalarMappable` 섞기 
</span>  <span class="c1"># -1 부터 1 까지 균일한 간격(periods=10)의 array([])
</span>  <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">periods</span><span class="p">)]</span>
  <span class="c1"># print(np.linspace(-1, 1, periods))
</span>  <span class="c1"># array([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,
</span>  <span class="c1">#       0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ])
</span>  <span class="c1">#
</span>  <span class="c1"># print(colors)
</span>  <span class="c1"># [(0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.2298057, 0.298717966, 0.753683153, 1.0),
</span>  <span class="c1">#  (0.3634607953411765, 0.4847836818509804, 0.9010188868941177, 1.0),
</span>  <span class="c1">#  (0.6672529243333334, 0.7791764569999999, 0.992959213, 1.0),
</span>  <span class="c1">#  (0.9193759889058823, 0.8312727235294118, 0.7828736304470588, 1.0),
</span>  <span class="c1">#  (0.9440545734235294, 0.5531534787490197, 0.4355484903137255, 1.0),
</span>  <span class="c1">#  (0.705673158, 0.01555616, 0.150232812, 1.0)]
</span>

  <span class="c1"># Train the model, but do so inside a loop so that we can periodically assess
</span>  <span class="c1"># loss metrics.
</span>  <span class="k">print</span><span class="p">(</span><span class="s">"Training model..."</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"RMSE (on training data):"</span><span class="p">)</span>
  <span class="n">root_mean_squared_errors</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">period</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">periods</span><span class="p">):</span>  <span class="c1"># (0, 10)
</span>    <span class="c1"># Train the model, starting from the prior state.
</span>    <span class="c1"># 모델을 학습, 이전 상태에서 시작
</span>    <span class="n">linear_regressor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
        <span class="n">input_fn</span><span class="o">=</span><span class="n">training_input_fn</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps_per_period</span>  <span class="c1"># =step/periods
</span>    <span class="p">)</span>
    <span class="c1"># Take a break and compute predictions.
</span>    <span class="c1"># 예측하기(학습된 모델 기반으로)
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="n">prediction_input_fn</span><span class="p">)</span>
    <span class="c1"># 예측된 결과 값만 가져오기
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>

    <span class="c1"># Compute loss.
</span>    <span class="n">root_mean_squared_error</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>  <span class="c1"># 제곱근 처리하기(RMSE)
</span>        <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">))</span>  <span class="c1"># 손실율 계산하기(MSE)
</span>    <span class="c1"># Occasionally print the current loss.
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"  period </span><span class="si">%02</span><span class="s">d : </span><span class="si">%0.2</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">period</span><span class="p">,</span> <span class="n">root_mean_squared_error</span><span class="p">))</span>
    <span class="c1"># Add the loss metrics from this period to our list.
</span>    <span class="n">root_mean_squared_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">root_mean_squared_error</span><span class="p">)</span>
    <span class="c1"># Finally, track the weights and biases over time.
</span>    <span class="c1"># 시간에 따른 가중치와 편향구하기
</span>    <span class="c1"># Apply some math to ensure that the data and line are plotted neatly.
</span>    <span class="c1"># 몇 가지 수학을 적용하여 데이터와 선이 깔끔하게 정리하기
</span>    <span class="c1"># Y 범위 (sample의 0 부터 Y(target) 최대 값)
</span>    <span class="n">y_extents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="n">my_label</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()])</span>

    <span class="c1"># 특성의 가중치
</span>    <span class="n">weight</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/</span><span class="si">%</span><span class="s">s/weights'</span> <span class="o">%</span> <span class="n">input_feature</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 편향(원점 기준의 한 절편, w1, w2, ..)
</span>    <span class="n">bias</span> <span class="o">=</span> <span class="n">linear_regressor</span><span class="o">.</span><span class="n">get_variable_value</span><span class="p">(</span><span class="s">'linear/linear_model/bias_weights'</span><span class="p">)</span>
    <span class="n">x_extents</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_extents</span> <span class="o">-</span> <span class="n">bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">weight</span>  <span class="c1"># 션형관계(y=d+w*x)를 이용한 X 구하기
</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'{x_extents} = ({y_extents} - {bias}) / {weight}'</span><span class="p">)</span>
    <span class="n">x_extents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x_extents</span><span class="p">,</span>
                                      <span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()),</span>
                           <span class="n">sample</span><span class="p">[</span><span class="n">my_feature</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">())</span>
    <span class="n">y_extents</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">x_extents</span> <span class="o">+</span> <span class="n">bias</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'{y_extents} = {weight} * {x_extents} + {bias}'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_extents</span><span class="p">,</span> <span class="n">y_extents</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">period</span><span class="p">])</span> 
  <span class="k">print</span><span class="p">(</span><span class="s">"Model training finished."</span><span class="p">)</span>

  <span class="c1"># Output a graph of loss metrics over periods.
</span>  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'RMSE'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Periods'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Root Mean Squared Error vs. Periods"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="k">print</span><span class="p">(</span><span class="n">root_mean_squared_errors</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">root_mean_squared_errors</span><span class="p">)</span>

  <span class="c1"># Output a table with calibration data.
</span>  <span class="n">calibration_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
  <span class="n">calibration_data</span><span class="p">[</span><span class="s">"predictions"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
  <span class="n">calibration_data</span><span class="p">[</span><span class="s">"targets"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
  <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">calibration_data</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

  <span class="k">print</span><span class="p">(</span><span class="s">"Final RMSE (on training data): </span><span class="si">%0.2</span><span class="s">f"</span> <span class="o">%</span> <span class="n">root_mean_squared_error</span><span class="p">)</span>
</code></pre></div>
<h2 id="1-180-rmse">작업 1: 180 이하의 RMSE 달성</h2>

<p>모델 초매개변수를 조정하여 타겟 분포와 더 잘 일치하도록 손실을 개선합니다.
5분이 지나도록 RMSE를 180 이하로 떨어뜨리지 못한 경우 해결 방법에을 확인하여 가능한 조합을 알아보세요.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">236.32</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">235.11</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">233.90</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">232.70</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">231.50</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">230.31</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">229.13</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">227.96</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">226.79</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">225.63</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
       <span class="n">predictions</span>  <span class="n">targets</span>
<span class="n">count</span>      <span class="mf">17000.0</span>  <span class="mf">17000.0</span>
<span class="n">mean</span>          <span class="mf">13.2</span>    <span class="mf">207.3</span>
<span class="n">std</span>           <span class="mf">10.9</span>    <span class="mf">116.0</span>
<span class="nb">min</span>            <span class="mf">0.0</span>     <span class="mf">15.0</span>
<span class="mi">25</span><span class="o">%</span>            <span class="mf">7.3</span>    <span class="mf">119.4</span>
<span class="mi">50</span><span class="o">%</span>           <span class="mf">10.6</span>    <span class="mf">180.4</span>
<span class="mi">75</span><span class="o">%</span>           <span class="mf">15.8</span>    <span class="mf">265.0</span>
<span class="nb">max</span>          <span class="mf">189.7</span>    <span class="mf">500.0</span>
<span class="n">Final</span> <span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span> <span class="mf">225.63</span>
</code></pre></div>
<p><img src="img/%EB%AA%A8%EB%8D%B8%20%EC%B4%88%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%20%EC%A1%B0%EC%A0%95.png" alt="모델 초매개변수 조정.png"></p>

<h3 id="part-606b64351882ea1d">해결 방법</h3>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">225.63</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">214.42</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">204.04</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">194.97</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">186.92</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">180.53</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">175.22</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">171.57</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">169.08</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">167.98</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
</code></pre></div>
<p><img src="img/%EB%AA%A8%EB%8D%B8%20%EC%B4%88%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%20%EC%A1%B0%EC%A0%95%20%ED%95%B4%EA%B2%B0.png" alt="모델 초매개변수 조정 해결.png"></p>

<p>이는 가능한 조합 중 하나일 뿐이며, 우수한 결과를 내는 다른 설정 조합이 있을 수 있습니다.<br>
일반적으로 이 실습의 목적은 최상의 설정을 찾는 것이 아니라 모델 구성을 조정하면 예측 품질에 어떠한 영향을 주는지 감을 잡는 것입니다.</p>

<h3 id="part-7ca94f58e45aacd0">모델 조정에 대한 표준 휴리스틱이 있는가?</h3>

<p>흔히 제기되는 질문입니다. 단적으로 말해, 다양한 초매개변수의 효과는 데이터에 따라 다릅니다.<br>
따라서 알기 쉽고 확고한 규칙은 존재하지 않으며, 실제 데이터로 테스트하는 과정이 필요합니다.</p>

<p>그러나 유용하게 참고할 만한 몇 가지 경험칙이 있습니다.</p>

<ul>
<li>학습 오차는 점차 감소합니다. 처음에는 급격히 감소하다가 학습이 수렴됨에 따라 결국 한계에 다다릅니다.</li>
<li>학습이 수렴되지 않았다면 더 오래 실행해 보세요.</li>
<li>학습 오차가 너무 천천히 감소하는 경우 학습률을 높이면 더 빨리 감소할 수 있습니다.

<ul>
<li>학습률이 너무 높다면 정반대 현상이 나타나기도 합니다.</li>
</ul>
</li>
<li>학습 오차가 크게 요동한다면 학습률을 낮춰보세요.

<ul>
<li>학습률을 낮추면서 단계 수 또는 배치 크기를 늘리면 좋은 결과가 나타나는 경우가 많습니다.</li>
</ul>
</li>
<li>배치 크기가 너무 작아도 불안정성이 나타날 수 있습니다. 처음에는 100, 1000 등의 큰 값을 사용한 후 성능이 악화되지 않는 선까지 낮추세요.</li>
</ul>

<p>효과는 데이터에 따라 달라지므로 이러한 경험칙을 무조건적으로 따라서는 안 됩니다.<br>
실험과 검증을 항상 반복하세요.</p>

<blockquote>
<p><strong>휴리스틱(heuristics)</strong>
발견법, 불충분한 시간이나 정보로 인하여 합리적인 판단을 할 수 없거나, 체계적이면서 합리적인
판단이 굳이 필요하지 않은 상황에서 사람들이 빠르게 사용할 수 있는 어림짐작의 방법이다.<br>
ex) 어떤 문제를 이해하기 어렵다면, 그림을 그려본다.</p>
</blockquote>

<h2 id="2">작업 2: 다른 특성 실험</h2>

<p><code>total_rooms</code> 특성을 <code>population</code> 특성으로 대체하면 결과가 개선되는지 확인해 봅니다.</p>

<p>이 부분은 최대 5분까지만 진행하시기 바랍니다.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">train_model</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">input_feature</span><span class="o">=</span><span class="s">"population"</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">Training</span> <span class="n">model</span><span class="o">...</span>
<span class="n">RMSE</span> <span class="p">(</span><span class="n">on</span> <span class="n">training</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">period</span> <span class="mi">00</span> <span class="p">:</span> <span class="mf">225.63</span>
  <span class="n">period</span> <span class="mi">01</span> <span class="p">:</span> <span class="mf">214.62</span>
  <span class="n">period</span> <span class="mi">02</span> <span class="p">:</span> <span class="mf">204.67</span>
  <span class="n">period</span> <span class="mi">03</span> <span class="p">:</span> <span class="mf">195.94</span>
  <span class="n">period</span> <span class="mi">04</span> <span class="p">:</span> <span class="mf">189.12</span>
  <span class="n">period</span> <span class="mi">05</span> <span class="p">:</span> <span class="mf">183.81</span>
  <span class="n">period</span> <span class="mi">06</span> <span class="p">:</span> <span class="mf">180.34</span>
  <span class="n">period</span> <span class="mi">07</span> <span class="p">:</span> <span class="mf">178.18</span>
  <span class="n">period</span> <span class="mi">08</span> <span class="p">:</span> <span class="mf">176.70</span>
  <span class="n">period</span> <span class="mi">09</span> <span class="p">:</span> <span class="mf">176.10</span>
<span class="n">Model</span> <span class="n">training</span> <span class="n">finished</span><span class="o">.</span>
</code></pre></div>
<p><img src="img/%EC%9E%91%EC%97%852.png" alt="작업2.png"></p>

<h2 id="reference">Reference</h2>

<p><a href="https://developers.google.com/machine-learning/glossary/?hl=ko" rel="nofollow" target="_blank">머신러닝 용어집</a></p>

</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Portal2312&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Portal2312&#39;s blog</li><li><a class="u-email" href="mailto:portal2312@gmail.com">portal2312@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg> <span class="username">portal2312</span></a></li><li><a href="https://www.twitter.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">portal2312</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Welcome to my blog.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
