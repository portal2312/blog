<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Lambda (람다) | Portal2312&#39;s blog</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Lambda (람다)" />
<meta name="author" content="mkkim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="모델 개발자는 람다 = 스칼라(=정규화율 이라고도 함)를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정합니다. 즉, 모델 개발자는 다음을 수행하는 것을 목표로 합니다:" />
<meta property="og:description" content="모델 개발자는 람다 = 스칼라(=정규화율 이라고도 함)를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정합니다. 즉, 모델 개발자는 다음을 수행하는 것을 목표로 합니다:" />
<link rel="canonical" href="/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/011.%20Regularization:%20Simplicity%20(%EB%8B%A8%EC%88%9C%EC%84%B1%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EC%A0%95%EA%B7%9C%ED%99%94,%2045%20min)/004.%20%EB%9E%8C%EB%8B%A4.html" />
<meta property="og:url" content="/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/011.%20Regularization:%20Simplicity%20(%EB%8B%A8%EC%88%9C%EC%84%B1%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EC%A0%95%EA%B7%9C%ED%99%94,%2045%20min)/004.%20%EB%9E%8C%EB%8B%A4.html" />
<meta property="og:site_name" content="Portal2312&#39;s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-12-02T16:38:51+09:00" />
<script type="application/ld+json">
{"description":"모델 개발자는 람다 = 스칼라(=정규화율 이라고도 함)를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정합니다. 즉, 모델 개발자는 다음을 수행하는 것을 목표로 합니다:","headline":"Lambda (람다)","dateModified":"2019-12-02T16:38:51+09:00","datePublished":"2019-12-02T16:38:51+09:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/011.%20Regularization:%20Simplicity%20(%EB%8B%A8%EC%88%9C%EC%84%B1%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EC%A0%95%EA%B7%9C%ED%99%94,%2045%20min)/004.%20%EB%9E%8C%EB%8B%A4.html"},"url":"/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/011.%20Regularization:%20Simplicity%20(%EB%8B%A8%EC%88%9C%EC%84%B1%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EC%A0%95%EA%B7%9C%ED%99%94,%2045%20min)/004.%20%EB%9E%8C%EB%8B%A4.html","author":{"@type":"Person","name":"mkkim"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href='/blog/assets/main.css'><link type="application/atom+xml" rel="alternate" href="/blog/feed.xml" title="Portal2312's blog" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113063601-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script src='/blog/dist/js/common.bundle.js'></script>
</head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/blog/">Portal2312&#39;s blog</a>
    <nav class="site-nav">
    <input type="checkbox" id="nav-trigger" class="nav-trigger" />
    <label for="nav-trigger">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
        </svg>
      </span>
    </label>

    <div class="trigger"><a class="page-link" href="/blog/about.html">
            About
          </a><a class="page-link" href="/blog/posts.html">
            Posts
          </a><a class="page-link" href="/blog/history.html">
            History
          </a><a class="page-link" href="/blog/docs/index.html">
            Docs
          </a></div>
  </nav>
  </div>
  <div class="scroll-indicator-container">
  <div class="scroll-indicator-bar" id="scrollIndicatorBar"></div>
</div>

</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1>Lambda (람다)</h1>

  <div>
    <h2>Table of contents</h2>
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#l2">플레이 그라운드 실습: L2 정규화 검사</a></li>
<li class="toc-entry toc-h2"><a href="#part-37875908cec8c36">이해도</a>
<ul>
<li class="toc-entry toc-h3"><a href="#l2">L2 정규화</a></li>
<li class="toc-entry toc-h3"><a href="#l2">L2 정규화와 상관 특성</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#reference">Reference</a></li>
</ul><p>모델 개발자는 람다 = 스칼라(=정규화율 이라고도 함)를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정합니다.
즉, 모델 개발자는 다음을 수행하는 것을 목표로 합니다:</p>

<p>$$
\text{최소화 (손실 (데이터|모델)} + \lambda \text{복잡도 (모델))}
$$</p>

<p>L2 정규화를 수행하면 모델에 다음과 같은 효과를 줄 수 있습니다.</p>

<ul>
<li>가중치 값을 0으로 유도(정확히 0은 아님)</li>
<li>정규 (종 모양 또는 가우시안) 분포를 사용하여 가중치 평균을 0으로 유도</li>
</ul>

<p>람다 값을 높이면 정규화 효과가 강화됩니다.</p>

<p>예를 들어 높은 람다 값에 대한 가중치 히스토그램:</p>

<p><img src="HighLambda.svg" alt="HighLambda.svg"></p>

<p>람다 값을 낮추면:</p>

<p><img src="LowLambda.svg" alt="LowLambda.svg"></p>

<p>람다 값을 선택할 때 세워야 할 목표: <strong>단순성</strong> &amp; <strong>학습 데이터 적합성</strong> 사이의 균형</p>

<p>람다 값: 높음 -&gt; 모델: 단순 -&gt; 데이터 과소적합 -&gt; 모델은 유용한 예측을 수행할 만큼 학습 데이터에 대해 충분히 학습하지 못함.</p>

<p>람다 값: 낮음 -&gt; 모델: 복잡 -&gt; 데이터가 과적합 -&gt; 모델이 학습 데이터의 특수성을 너무 많이 학습 -&gt; 새로운 데이터로 일반화하지 못함.</p>

<blockquote>
<p><strong>참고:</strong>
람다를 0 으로 설정하면 정규화가 완전히 제거됩니다.
이 경우 학습이 손실을 최소화하는 데에만 초점을 맞추게 되어 가장 높은 수준의 과적합 위험을 낳습니다.</p>
</blockquote>

<p>이상적인 람다 값은 이전에는 볼 수 없었던 새로운 데이터로 일반화된 모델을 생성합니다.<br>
불행히도 람다의 이상적인 가치는 데이터에 따라 다르므로 약간의 튜닝이 필요합니다.</p>

<p><strong>L2 정규화 와 학습률:</strong></p>

<p>학습률과 람다는 밀접하게 연결되어 있습니다.
강력한 L2 정규화 값은 특성 가중치를 0에 가깝게 유도하는 경향이 있습니다.
낮은 학습률(조기 중단 포함)도 종종 같은 효과를 가져오는데 이는 0과의 보폭 차이가 그다지 크지 않기 때문입니다.
결과적으로 학습률과 람다를 동시에 변경하면 혼동스러운 효과를 낳을 수 있습니다.</p>

<p><strong>조기 중단</strong>이란 모델이 완전히 수렴되기 전에 학습을 끝내는 것을 뜻합니다.
실제로 학습이 온라인 (연속적) 방식일 경우 일정 부분 암묵적으로 학습을 조기에 중단하는 경우가 많습니다.
즉, 일부 새로운 추세에는 아직 수렴을 위한 데이터가 충분하지 않습니다.</p>

<p>이미 언급했듯이 정규화 매개변수 변경으로 인한 효과는
학습률 또는 반복 횟수의 변경으로 인한 효과와의 혼동을 일으킬 수 있습니다.</p>

<p>한 가지 유용한 방법(고정된 데이터 배치를 가지고 학습하는 경우)은 조기 중단의 영향이 발생하지 않도록 반복 횟수를 충분히 높이는 것입니다.</p>

<h2 id="l2">
<a class="anchor" href="#l2" aria-hidden="true"><span class="octicon octicon-link"></span></a>플레이 그라운드 실습: L2 정규화 검사</h2>

<p>이 실습에는 노이즈가 있는 작은 규모의 학습 데이터 세트가 포함되어 있습니다. 이런 설정에서는 과적합이 가장 문제가 됩니다. 하지만 정규화를 사용하면 문제 해결이 도움이 될 것입니다.</p>

<p>정규화율을 0에서 0.3으로 높이면 다음과 같은 효과가 발생합니다.</p>

<p>테스트 손실이 대폭 감소합니다.</p>

<p>참고: 테스트 손실은 감소하지만 학습 손실은 증가합니다.
복잡도에 페널티를 주기 위해 손실 함수에 또 다른 항을 추가했으므로 이는 예상치 못한 결과는 아닙니다.<br>
궁극적으로 중요한 것은 <strong>테스트 손실</strong>입니다.<br>
모델이 새 데이터에 대해 좋은 예측을 내릴 수 있는 능력의 진정한 척도이기 때문입니다.</p>

<p>테스트 손실과 학습 손실 사이의 델타 값이 대폭 감소합니다.
특성과 일부 특성 교차에 대한 가중치의 절대값이 낮으므로 모델 복잡도도 떨어집니다.
데이터 세트의 무작위성을 고려해 볼 때 어떤 정규화율이 가장 좋은 결과를 가져올지 예측하기는 불가능합니다.
여기에서는 정규화율 0.3 또는 1에서 일반적으로 가장 낮은 테스트 손실이 발생했습니다.</p>

<h2 id="part-37875908cec8c36">
<a class="anchor" href="#part-37875908cec8c36" aria-hidden="true"><span class="octicon octicon-link"></span></a>이해도</h2>

<h3 id="l2">
<a class="anchor" href="#l2" aria-hidden="true"><span class="octicon octicon-link"></span></a>L2 정규화</h3>

<p>100개의 입력 특성이 있는 선형 모델을 떠올려 보세요.
- 10개는 매우 유용합니다.
- 90개는 유용하지 않습니다.
모든 특성이 -1과 1 사이의 값을 갖는다고 가정했을 때 다음 중 참인 내용은 무엇일까요?</p>

<ul>
<li><p>모델이 일부 <strong>유용하지 않은</strong> 특성에 대해 적정 가중치를 학습하게 됨:<br>
놀랍게도 유용하지 않은 특성이 라벨과 상관 관계가 있을 때 이러한 일이 발생할 수 있습니다.<br>
이 경우 모델은 유용한 특성에 부여되어야 할 '크레딧'의 일부를 그러한 유용하지 않은 특성에 잘못 부여하게 됩니다.</p></li>
<li><p>L2 정규화는 많은 유용하지 않은 가중치를 (정확히는 아니지만) 0.0에 가깝게 유도 함.</p></li>
</ul>

<h3 id="l2">
<a class="anchor" href="#l2" aria-hidden="true"><span class="octicon octicon-link"></span></a>L2 정규화와 상관 특성</h3>

<p>밀접한 상관 관계가 두 개의 특성을 떠올려 보세요.
이 두 특성은 서로 거의 동일하지만 둘 중 하나의 특성에는 임의의 노이즈가 조금 포함되어 있습니다.
L2 정규화를 사용해 이 모델을 학습한다면 이러한 두 특성에 대한 가중치는 어떻게 될까요?</p>

<ul>
<li>두 특성 모두 대체로 동일하며 적정한 가중치를 갖게 됩니다:<br>
L2 정규화는 두 가지 특성 중 하나만 모델에 포함한 경우의 대략 절반 수준인 대체로 동일한 가중치를 향하여 특성을 이끌어 갑니다.</li>
</ul>

<h2 id="reference">
<a class="anchor" href="#reference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reference</h2>

<p><a href="https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda?hl=ko">https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda?hl=ko</a></p>

  </div>

<div>
  <p>모델 개발자는 람다 = 스칼라(=정규화율 이라고도 함)를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정합니다.
즉, 모델 개발자는 다음을 수행하는 것을 목표로 합니다:</p>

<p>$$
\text{최소화 (손실 (데이터|모델)} + \lambda \text{복잡도 (모델))}
$$</p>

<p>L2 정규화를 수행하면 모델에 다음과 같은 효과를 줄 수 있습니다.</p>

<ul>
<li>가중치 값을 0으로 유도(정확히 0은 아님)</li>
<li>정규 (종 모양 또는 가우시안) 분포를 사용하여 가중치 평균을 0으로 유도</li>
</ul>

<p>람다 값을 높이면 정규화 효과가 강화됩니다.</p>

<p>예를 들어 높은 람다 값에 대한 가중치 히스토그램:</p>

<p><img src="HighLambda.svg" alt="HighLambda.svg"></p>

<p>람다 값을 낮추면:</p>

<p><img src="LowLambda.svg" alt="LowLambda.svg"></p>

<p>람다 값을 선택할 때 세워야 할 목표: <strong>단순성</strong> &amp; <strong>학습 데이터 적합성</strong> 사이의 균형</p>

<p>람다 값: 높음 -&gt; 모델: 단순 -&gt; 데이터 과소적합 -&gt; 모델은 유용한 예측을 수행할 만큼 학습 데이터에 대해 충분히 학습하지 못함.</p>

<p>람다 값: 낮음 -&gt; 모델: 복잡 -&gt; 데이터가 과적합 -&gt; 모델이 학습 데이터의 특수성을 너무 많이 학습 -&gt; 새로운 데이터로 일반화하지 못함.</p>

<blockquote>
<p><strong>참고:</strong>
람다를 0 으로 설정하면 정규화가 완전히 제거됩니다.
이 경우 학습이 손실을 최소화하는 데에만 초점을 맞추게 되어 가장 높은 수준의 과적합 위험을 낳습니다.</p>
</blockquote>

<p>이상적인 람다 값은 이전에는 볼 수 없었던 새로운 데이터로 일반화된 모델을 생성합니다.<br>
불행히도 람다의 이상적인 가치는 데이터에 따라 다르므로 약간의 튜닝이 필요합니다.</p>

<p><strong>L2 정규화 와 학습률:</strong></p>

<p>학습률과 람다는 밀접하게 연결되어 있습니다.
강력한 L2 정규화 값은 특성 가중치를 0에 가깝게 유도하는 경향이 있습니다.
낮은 학습률(조기 중단 포함)도 종종 같은 효과를 가져오는데 이는 0과의 보폭 차이가 그다지 크지 않기 때문입니다.
결과적으로 학습률과 람다를 동시에 변경하면 혼동스러운 효과를 낳을 수 있습니다.</p>

<p><strong>조기 중단</strong>이란 모델이 완전히 수렴되기 전에 학습을 끝내는 것을 뜻합니다.
실제로 학습이 온라인 (연속적) 방식일 경우 일정 부분 암묵적으로 학습을 조기에 중단하는 경우가 많습니다.
즉, 일부 새로운 추세에는 아직 수렴을 위한 데이터가 충분하지 않습니다.</p>

<p>이미 언급했듯이 정규화 매개변수 변경으로 인한 효과는
학습률 또는 반복 횟수의 변경으로 인한 효과와의 혼동을 일으킬 수 있습니다.</p>

<p>한 가지 유용한 방법(고정된 데이터 배치를 가지고 학습하는 경우)은 조기 중단의 영향이 발생하지 않도록 반복 횟수를 충분히 높이는 것입니다.</p>

<h2 id="l2">플레이 그라운드 실습: L2 정규화 검사</h2>

<p>이 실습에는 노이즈가 있는 작은 규모의 학습 데이터 세트가 포함되어 있습니다. 이런 설정에서는 과적합이 가장 문제가 됩니다. 하지만 정규화를 사용하면 문제 해결이 도움이 될 것입니다.</p>

<p>정규화율을 0에서 0.3으로 높이면 다음과 같은 효과가 발생합니다.</p>

<p>테스트 손실이 대폭 감소합니다.</p>

<p>참고: 테스트 손실은 감소하지만 학습 손실은 증가합니다.
복잡도에 페널티를 주기 위해 손실 함수에 또 다른 항을 추가했으므로 이는 예상치 못한 결과는 아닙니다.<br>
궁극적으로 중요한 것은 <strong>테스트 손실</strong>입니다.<br>
모델이 새 데이터에 대해 좋은 예측을 내릴 수 있는 능력의 진정한 척도이기 때문입니다.</p>

<p>테스트 손실과 학습 손실 사이의 델타 값이 대폭 감소합니다.
특성과 일부 특성 교차에 대한 가중치의 절대값이 낮으므로 모델 복잡도도 떨어집니다.
데이터 세트의 무작위성을 고려해 볼 때 어떤 정규화율이 가장 좋은 결과를 가져올지 예측하기는 불가능합니다.
여기에서는 정규화율 0.3 또는 1에서 일반적으로 가장 낮은 테스트 손실이 발생했습니다.</p>

<h2 id="part-37875908cec8c36">이해도</h2>

<h3 id="l2">L2 정규화</h3>

<p>100개의 입력 특성이 있는 선형 모델을 떠올려 보세요.
- 10개는 매우 유용합니다.
- 90개는 유용하지 않습니다.
모든 특성이 -1과 1 사이의 값을 갖는다고 가정했을 때 다음 중 참인 내용은 무엇일까요?</p>

<ul>
<li><p>모델이 일부 <strong>유용하지 않은</strong> 특성에 대해 적정 가중치를 학습하게 됨:<br>
놀랍게도 유용하지 않은 특성이 라벨과 상관 관계가 있을 때 이러한 일이 발생할 수 있습니다.<br>
이 경우 모델은 유용한 특성에 부여되어야 할 '크레딧'의 일부를 그러한 유용하지 않은 특성에 잘못 부여하게 됩니다.</p></li>
<li><p>L2 정규화는 많은 유용하지 않은 가중치를 (정확히는 아니지만) 0.0에 가깝게 유도 함.</p></li>
</ul>

<h3 id="l2">L2 정규화와 상관 특성</h3>

<p>밀접한 상관 관계가 두 개의 특성을 떠올려 보세요.
이 두 특성은 서로 거의 동일하지만 둘 중 하나의 특성에는 임의의 노이즈가 조금 포함되어 있습니다.
L2 정규화를 사용해 이 모델을 학습한다면 이러한 두 특성에 대한 가중치는 어떻게 될까요?</p>

<ul>
<li>두 특성 모두 대체로 동일하며 적정한 가중치를 갖게 됩니다:<br>
L2 정규화는 두 가지 특성 중 하나만 모델에 포함한 경우의 대략 절반 수준인 대체로 동일한 가중치를 향하여 특성을 이끌어 갑니다.</li>
</ul>

<h2 id="reference">Reference</h2>

<p><a href="https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda?hl=ko" rel="nofollow" target="_blank">https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda?hl=ko</a></p>

</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Portal2312&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Portal2312&#39;s blog</li><li><a class="u-email" href="mailto:portal2312@gmail.com">portal2312@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg> <span class="username">portal2312</span></a></li><li><a href="https://www.twitter.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">portal2312</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Welcome to my blog.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
