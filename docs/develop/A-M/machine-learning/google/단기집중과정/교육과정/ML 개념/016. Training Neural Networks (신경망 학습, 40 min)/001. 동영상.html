<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>신경망 학습 | Portal2312&#39;s blog</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="신경망 학습" />
<meta name="author" content="mkkim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="역전파는 신경망의 가장 일반적인 학습 알고리즘입니다. 다계층 신경망에서 경사하강법을 사용하려면 이 알고리즘이 필요합니다. 텐서플로우는 역전파를 자동으로 처리하므로 알고리즘을 자세히 이해할 필요는 없습니다. 이 알고리즘의 원리를 이해하려면 역전파 알고리즘 시각적 설명을 참조하세요." />
<meta property="og:description" content="역전파는 신경망의 가장 일반적인 학습 알고리즘입니다. 다계층 신경망에서 경사하강법을 사용하려면 이 알고리즘이 필요합니다. 텐서플로우는 역전파를 자동으로 처리하므로 알고리즘을 자세히 이해할 필요는 없습니다. 이 알고리즘의 원리를 이해하려면 역전파 알고리즘 시각적 설명을 참조하세요." />
<link rel="canonical" href="/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/016.%20Training%20Neural%20Networks%20(%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5,%2040%20min)/001.%20%EB%8F%99%EC%98%81%EC%83%81.html" />
<meta property="og:url" content="/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/016.%20Training%20Neural%20Networks%20(%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5,%2040%20min)/001.%20%EB%8F%99%EC%98%81%EC%83%81.html" />
<meta property="og:site_name" content="Portal2312&#39;s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-12-02T16:38:51+09:00" />
<script type="application/ld+json">
{"description":"역전파는 신경망의 가장 일반적인 학습 알고리즘입니다. 다계층 신경망에서 경사하강법을 사용하려면 이 알고리즘이 필요합니다. 텐서플로우는 역전파를 자동으로 처리하므로 알고리즘을 자세히 이해할 필요는 없습니다. 이 알고리즘의 원리를 이해하려면 역전파 알고리즘 시각적 설명을 참조하세요.","headline":"신경망 학습","dateModified":"2019-12-02T16:38:51+09:00","datePublished":"2019-12-02T16:38:51+09:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/016.%20Training%20Neural%20Networks%20(%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5,%2040%20min)/001.%20%EB%8F%99%EC%98%81%EC%83%81.html"},"url":"/blog/docs/develop/A-M/machine-learning/google/%EB%8B%A8%EA%B8%B0%EC%A7%91%EC%A4%91%EA%B3%BC%EC%A0%95/%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/ML%20%EA%B0%9C%EB%85%90/016.%20Training%20Neural%20Networks%20(%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%ED%95%99%EC%8A%B5,%2040%20min)/001.%20%EB%8F%99%EC%98%81%EC%83%81.html","author":{"@type":"Person","name":"mkkim"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href='/blog/assets/main.css'><link type="application/atom+xml" rel="alternate" href="/blog/feed.xml" title="Portal2312's blog" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113063601-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script src='/blog/dist/js/common.bundle.js'></script>
</head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/blog/">Portal2312&#39;s blog</a>
    <nav class="site-nav">
    <input type="checkbox" id="nav-trigger" class="nav-trigger" />
    <label for="nav-trigger">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
        </svg>
      </span>
    </label>

    <div class="trigger"><a class="page-link" href="/blog/about.html">
            About
          </a><a class="page-link" href="/blog/posts.html">
            Posts
          </a><a class="page-link" href="/blog/history.html">
            History
          </a><a class="page-link" href="/blog/docs/index.html">
            Docs
          </a></div>
  </nav>
  </div>
  <div class="scroll-indicator-container">
  <div class="scroll-indicator-bar" id="scrollIndicatorBar"></div>
</div>

</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1>신경망 학습</h1>

  <div>
    <h2>Table of contents</h2>
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#reference">Reference</a></li>
</ul><p>역전파는 신경망의 가장 일반적인 학습 알고리즘입니다.
다계층 신경망에서 경사하강법을 사용하려면 이 알고리즘이 필요합니다.
텐서플로우는 역전파를 자동으로 처리하므로 알고리즘을 자세히 이해할 필요는 없습니다.
이 알고리즘의 원리를 이해하려면 <a href="https://developers.google.com/machine-learning/crash-course/backprop-scroll/">역전파 알고리즘 시각적 설명</a>을 참조하세요.</p>

<p>이 설명 과정을 진행하면서 다음 사항에 주목하세요:</p>

<ul>
<li>데이터가 그래프를 통과하는 방식</li>
<li>동적 프로그래밍을 사용하면 기하급수적으로 증가하는 그래프 통과 경로를 일일이 계산할 필요가 없는 이유.
여기에서 '동적 프로그래밍'은 정방향 및 역방향 전달에서 중간 결과를 기록함을 의미.</li>
</ul>

<p>학습 목표:</p>

<ul>
<li>역전파에 대한 감을 익힙니다.</li>
</ul>

<p>내용:</p>

<ul>
<li><p>경사: 역전파에서는 학습할 사례를 서로 변별 가능하게 해줌 (중요)</p></li>
<li><p>TF 역전파의 내부적인 사항을 알아서 처리해줌.</p></li>
<li><p>여러 함수간 나타나는 한두가지의 작은 불연속성은 괜찮지만 일반적으로 신경망으로 학습하려면 미분 가능한 함수가 필요합니다.</p></li>
<li><p>경사가 사라지는 경우: 신경망이 너무 깊어 모델 아래 쪽으로 갈 수록 비율이 악화되면서 학습 속도가 상당히 느려집니다. 이 때 ReLU 사용하면 좋다. (그 외 다른 방법도 존재)
하지만 일반적으로 가능한 경우 모델의 깊이를 최소 효과 깊이로 제안하는 것이 좋다.</p></li>
<li><p>학습율이 너무 높아지면 불완전성이 커지고 모델에서 NaN 값을 얻게 됨.</p></li>
<li><p>0 이하의 값이 나오지 않도록 강력한 제한을 두기 때문에 모든 값이 0 미만으로 나오는 경우 역전파를 얻을 수 있는 경사가 나오지 않게 되서 실행 가능한 ReLU 층으로 돌아 갈 수 없다.
이러한 상황이 발생하지 않는지 주의깊게 살피고 다른 시작점이나 낮은 학습율을 사용해서 다시 시도해보는 것이 좋다.</p></li>
<li>
<p>모델 학습시 정규화된 특성 값을 가져오는 것이 유용.</p>

<ul>
<li>사례들의 크기가 서로 비슷한 경우 정규화된 값을 사용하면 신경망의 전환 속도가 빨라짐.</li>
<li>정확한 크기는 중요하지 않다.</li>
<li>
<em>-1</em> ~ <em>+1</em> 사용하는 것이 좋다. (하지만 입력 값의 크기가 비슷시 -5~+5 나 -1~+1 상관없음)</li>
</ul>
</li>
<li>
<p>드롭아웃</p>

<ul>
<li>반복하면 정규화가 강력해지나 모든 사례에 타고 들어가게 되면 모델이 극단적으로 단순해지고 쓸모 없게됨</li>
<li>하지 않으면 모델의 복잡성이 그대로 유지</li>
<li>적당히 사용하면 알맞게 사용하면 정규화가 됨</li>
</ul>
</li>
</ul>

<h2 id="reference">
<a class="anchor" href="#reference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reference</h2>

<p><a href="https://developers.google.com/machine-learning/crash-course/training-neural-networks/video-lecture">https://developers.google.com/machine-learning/crash-course/training-neural-networks/video-lecture</a></p>

  </div>

<div>
  <p>역전파는 신경망의 가장 일반적인 학습 알고리즘입니다.
다계층 신경망에서 경사하강법을 사용하려면 이 알고리즘이 필요합니다.
텐서플로우는 역전파를 자동으로 처리하므로 알고리즘을 자세히 이해할 필요는 없습니다.
이 알고리즘의 원리를 이해하려면 <a href="https://developers.google.com/machine-learning/crash-course/backprop-scroll/" rel="nofollow" target="_blank">역전파 알고리즘 시각적 설명</a>을 참조하세요.</p>

<p>이 설명 과정을 진행하면서 다음 사항에 주목하세요:</p>

<ul>
<li>데이터가 그래프를 통과하는 방식</li>
<li>동적 프로그래밍을 사용하면 기하급수적으로 증가하는 그래프 통과 경로를 일일이 계산할 필요가 없는 이유.
여기에서 '동적 프로그래밍'은 정방향 및 역방향 전달에서 중간 결과를 기록함을 의미.</li>
</ul>

<p>학습 목표:</p>

<ul>
<li>역전파에 대한 감을 익힙니다.</li>
</ul>

<p>내용:</p>

<ul>
<li><p>경사: 역전파에서는 학습할 사례를 서로 변별 가능하게 해줌 (중요)</p></li>
<li><p>TF 역전파의 내부적인 사항을 알아서 처리해줌.</p></li>
<li><p>여러 함수간 나타나는 한두가지의 작은 불연속성은 괜찮지만 일반적으로 신경망으로 학습하려면 미분 가능한 함수가 필요합니다.</p></li>
<li><p>경사가 사라지는 경우: 신경망이 너무 깊어 모델 아래 쪽으로 갈 수록 비율이 악화되면서 학습 속도가 상당히 느려집니다. 이 때 ReLU 사용하면 좋다. (그 외 다른 방법도 존재)
하지만 일반적으로 가능한 경우 모델의 깊이를 최소 효과 깊이로 제안하는 것이 좋다.</p></li>
<li><p>학습율이 너무 높아지면 불완전성이 커지고 모델에서 NaN 값을 얻게 됨.</p></li>
<li><p>0 이하의 값이 나오지 않도록 강력한 제한을 두기 때문에 모든 값이 0 미만으로 나오는 경우 역전파를 얻을 수 있는 경사가 나오지 않게 되서 실행 가능한 ReLU 층으로 돌아 갈 수 없다.
이러한 상황이 발생하지 않는지 주의깊게 살피고 다른 시작점이나 낮은 학습율을 사용해서 다시 시도해보는 것이 좋다.</p></li>
<li>
<p>모델 학습시 정규화된 특성 값을 가져오는 것이 유용.</p>

<ul>
<li>사례들의 크기가 서로 비슷한 경우 정규화된 값을 사용하면 신경망의 전환 속도가 빨라짐.</li>
<li>정확한 크기는 중요하지 않다.</li>
<li>
<em>-1</em> ~ <em>+1</em> 사용하는 것이 좋다. (하지만 입력 값의 크기가 비슷시 -5~+5 나 -1~+1 상관없음)</li>
</ul>
</li>
<li>
<p>드롭아웃</p>

<ul>
<li>반복하면 정규화가 강력해지나 모든 사례에 타고 들어가게 되면 모델이 극단적으로 단순해지고 쓸모 없게됨</li>
<li>하지 않으면 모델의 복잡성이 그대로 유지</li>
<li>적당히 사용하면 알맞게 사용하면 정규화가 됨</li>
</ul>
</li>
</ul>

<h2 id="reference">Reference</h2>

<p><a href="https://developers.google.com/machine-learning/crash-course/training-neural-networks/video-lecture" rel="nofollow" target="_blank">https://developers.google.com/machine-learning/crash-course/training-neural-networks/video-lecture</a></p>

</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Portal2312&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Portal2312&#39;s blog</li><li><a class="u-email" href="mailto:portal2312@gmail.com">portal2312@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg> <span class="username">portal2312</span></a></li><li><a href="https://www.twitter.com/portal2312"><svg class="svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">portal2312</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Welcome to my blog.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
